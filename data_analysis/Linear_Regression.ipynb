{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winning_chances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WCL database\n",
    "\n",
    "First, we calculate the winning chance for each evaluation and calculate the WCL (Winning Chance Loss) for each move. \n",
    "\n",
    "We then reorganize the data to get WCL for each player and each game, i. e. one line for White and one for Black.\n",
    "\n",
    "This is the data we then use for our linear regression.\n",
    "\n",
    "As an example and to limit CPU usage, only files with depth 20 are used here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_bins = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games_20.csv\")\n",
    "\n",
    "# table=winning_chances.compute_winning_chance_table(df) # re-compute the winning chance table\n",
    "table=pd.read_csv(\"table_20.csv\") # load pre-computed winning chance table for eval depth 20\n",
    "#table=pd.read_csv(\"winning_chances_all_moves.csv\") # load pre-computed winning chance table for all games\n",
    "summary_table=winning_chances.create_summary_table(df,mistake_bins=mistake_bins,winning_chance_table=table)\n",
    "summary_table.to_csv(\"summary_table_20.csv\",index=False)\n",
    "\n",
    "#summary_table=pd.read_csv(\"big_summary_table.csv\") # Load pre-computed summary table of all games\n",
    "\n",
    "# summary_table=pd.read_csv(\"summary_table_20.csv\") # Load pre-computed summary table of games with eval depth 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "\n",
    "Perform a linear regression on the summary table. \n",
    "\n",
    "We use the following features:\n",
    "\n",
    "- Number of mistakes in each bin (each bin corresponding to a different gravity of mistake)\n",
    "- Opening\n",
    "- Result\n",
    "- Total number of moves binned\n",
    "\n",
    "The last three features are categorical, we use a one-hot encoder to take them into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_Openings = 70  # Number of top openings to consider\n",
    "Color_Player = 'White'   # Player color to analyze ('White' or 'Black')\n",
    "categorical_features = ['Opening', 'Result', 'TotalMovesInterval']  # Initial categorical features (Removed 'TotalMovesInterval' here)\n",
    "numerical_features = []                 # Initial numerical features\n",
    "total_moves_bins = [0, 40, 60, 80, 100, 120, np.inf]  # Bins for total moves\n",
    "\n",
    "# Preprocess 'Opening' column to group less frequent openings as 'Other'\n",
    "top_openings = summary_table['Opening'].value_counts().nlargest(Number_of_Openings).index.tolist()\n",
    "summary_table['Opening'] = summary_table['Opening'].apply(lambda x: x if x in top_openings else 'Other')\n",
    "\n",
    "# Filter the summary table for the specified player color\n",
    "new_summary_table = summary_table[summary_table['Player'] == Color_Player].copy()\n",
    "\n",
    "# Define mistake labels based on columns after 'AWCL'\n",
    "start_index = new_summary_table.columns.get_loc('AWCL') + 1\n",
    "mistake_labels = list(new_summary_table.columns[start_index:])\n",
    "\n",
    "# Update numerical features to include mistake labels\n",
    "numerical_features += mistake_labels\n",
    "\n",
    "# Define total moves labels based on the bins\n",
    "total_moves_labels = [\n",
    "    f'({total_moves_bins[i]},{total_moves_bins[i+1]}]' if not np.isinf(total_moves_bins[i + 1]) else f'({total_moves_bins[i]},∞]'\n",
    "    for i in range(len(total_moves_bins) - 1)\n",
    "]\n",
    "\n",
    "# Create 'TotalMovesInterval' using pd.cut\n",
    "new_summary_table['TotalMovesInterval'] = pd.cut(\n",
    "    new_summary_table['TotalMoves'],\n",
    "    bins=total_moves_bins,\n",
    "    labels=total_moves_labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "new_summary_table = new_summary_table.dropna(subset=['Elo'])\n",
    "\n",
    "# Process categorical features\n",
    "for col in categorical_features:\n",
    "    # Convert to 'category' dtype\n",
    "    new_summary_table[col] = new_summary_table[col].astype('category')\n",
    "    # Add 'Unknown' to categories if not present\n",
    "    if 'Unknown' not in new_summary_table[col].cat.categories:\n",
    "        new_summary_table[col] = new_summary_table[col].cat.add_categories(['Unknown'])\n",
    "    # Fill NaN values with 'Unknown'\n",
    "    new_summary_table[col] = new_summary_table[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features (mistake intervals)\n",
    "new_summary_table[numerical_features] = new_summary_table[numerical_features].fillna(0)\n",
    "\n",
    "# Define target variable\n",
    "y = new_summary_table['Elo']\n",
    "\n",
    "# Define features\n",
    "X = new_summary_table[categorical_features + numerical_features]\n",
    "\n",
    "# Split the data with stratification on binned 'Elo' values\n",
    "y_binned = pd.qcut(y, q=10, duplicates='drop')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=40,\n",
    "    stratify=y_binned\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to apply OneHotEncoder to categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through numerical features unchanged\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared Score (R²): {r2:.2f}')\n",
    "\n",
    "# Calculate percentage of predictions within a threshold\n",
    "absolute_errors = np.abs(y_pred - y_test)\n",
    "threshold = 300\n",
    "within_threshold = np.sum(absolute_errors <= threshold)\n",
    "total_predictions = len(y_test)\n",
    "percentage_within_threshold = (within_threshold / total_predictions) * 100\n",
    "\n",
    "print(f\"Percentage of predictions within ±{threshold} Elo: {percentage_within_threshold:.2f}%\")\n",
    "\n",
    "# Get the names of the categorical features after one-hot encoding\n",
    "onehot_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine with numerical feature names\n",
    "all_feature_names = np.concatenate([onehot_feature_names, numerical_features])\n",
    "coefficients = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the coefficients by absolute value\n",
    "coef_df['AbsCoefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='AbsCoefficient', ascending=False)\n",
    "\n",
    "# Display the top 5 features with the highest absolute coefficients\n",
    "# print(\"\\nTop 5 features by absolute coefficient value:\")\n",
    "# print(coef_df[['Feature', 'Coefficient']].head(5))\n",
    "\n",
    "mistake_coef_df = coef_df[coef_df['Feature'].isin(mistake_labels)]\n",
    "\n",
    "# Display the coefficients for the mistake features\n",
    "# print(\"\\nCoefficients for the mistake labels:\")\n",
    "# print(mistake_coef_df[['Feature', 'Coefficient']])\n",
    "print(f\"min: {y_pred.min()}\")\n",
    "print(f\"max: {y_pred.max()}\")\n",
    "print(f\"mean: {y_pred.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_coefficients = mistake_coef_df.set_index('Feature')['Coefficient'].to_dict()\n",
    "mistake_coefficients = {k: abs(v) for k, v in mistake_coefficients.items()}\n",
    "# Step 2: Compute 'WeightedMistakeScore' using the coefficients\n",
    "# Vectorized calculation for efficiency\n",
    "coefficients_series = pd.Series(mistake_coefficients)\n",
    "new_summary_table['WeightedMistakeScore'] = new_summary_table[mistake_labels].dot(coefficients_series)\n",
    "\n",
    "# Step 3: Create Elo bins and labels\n",
    "elo_bins = [1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800]\n",
    "elo_labels = []\n",
    "for i in range(len(elo_bins) - 1):\n",
    "    lower = elo_bins[i]\n",
    "    upper = elo_bins[i + 1] - 1  # Subtract 1 to make the upper limit inclusive\n",
    "    label = f'{int(lower)}-{int(upper)}'\n",
    "    elo_labels.append(label)\n",
    "\n",
    "# Assign Elo bins to the data\n",
    "new_summary_table['EloBin'] = pd.cut(\n",
    "    new_summary_table['Elo'],\n",
    "    bins=elo_bins,\n",
    "    labels=elo_labels,\n",
    "    right=False,        # Left-inclusive intervals\n",
    "    include_lowest=True # Include the lowest value\n",
    ")\n",
    "\n",
    "# Remove rows with missing 'EloBin' values (if any)\n",
    "new_summary_table = new_summary_table.dropna(subset=['EloBin'])\n",
    "\n",
    "# Step 4: Compute average 'WeightedMistakeScore' per Elo bin\n",
    "avg_mistake_per_elo_bin = new_summary_table.groupby('EloBin')['WeightedMistakeScore'].mean().reset_index()\n",
    "\n",
    "# 1. Coefficient Bar Plot (Top 10 Features)\n",
    "# Get feature names after preprocessing\n",
    "onehot_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "feature_names = np.concatenate([onehot_feature_names, numerical_features])\n",
    "\n",
    "# Get coefficients from the linear regression model\n",
    "coefficients = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame for coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Calculate absolute coefficients\n",
    "coef_df['AbsCoefficient'] = coef_df['Coefficient'].abs()\n",
    "\n",
    "# Sort the coefficients in descending order of absolute value\n",
    "coef_df_sorted = coef_df.sort_values(by='AbsCoefficient', ascending=False)\n",
    "\n",
    "# Get the top 10 features by absolute coefficient value\n",
    "top_features = coef_df_sorted.head(10)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_features['Feature'], top_features['AbsCoefficient'], color='orange')\n",
    "plt.title('Top 10 Features by Absolute Coefficient Value (Linear Regression)')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Absolute Coefficient Value')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Predicted vs. Actual Elo Ratings Scatter Plot\n",
    "# Assuming y_test and y_pred are defined\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "plt.title('Predicted vs. Actual Elo Ratings (Linear Regression)')\n",
    "plt.xlabel('Actual Elo Rating')\n",
    "plt.ylabel('Predicted Elo Rating')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Residuals Plot\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.hlines(y=0, xmin=y_pred.min(), xmax=y_pred.max(), linestyles='dashed', colors='red')\n",
    "plt.title('Residuals Plot (Linear Regression)')\n",
    "plt.xlabel('Predicted Elo Rating')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Error Distribution Histogram\n",
    "# Plot histogram of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Residuals (Linear Regression)')\n",
    "plt.xlabel('Residuals (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Average Weighted Mistake Score per Elo Rating Bin Plot\n",
    "# Assuming 'new_summary_table' and 'avg_mistake_per_elo_bin' are defined\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_mistake_per_elo_bin['EloBin'], avg_mistake_per_elo_bin['WeightedMistakeScore'], marker='o')\n",
    "plt.title('Average Weighted Mistake Score per Elo Rating Bin (Linear Regression Model)')\n",
    "plt.xlabel('Elo Rating Bin')\n",
    "plt.ylabel('Average Weighted Mistake Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all necessary libraries are already imported and previous code has been executed\n",
    "# The pipeline 'pipeline' has been trained, and 'categorical_features', 'numerical_features',\n",
    "# and 'top_openings' are defined from your previous code.\n",
    "\n",
    "# Step 1: Select 20 games with Elo < 1500\n",
    "# Use the original 'new_summary_table' and filter for the specified player color if needed\n",
    "new_summary_table_low_elo = new_summary_table[new_summary_table['Elo'] < 1500].copy()\n",
    "\n",
    "# Check if there are at least 20 games; if not, adjust accordingly\n",
    "if len(new_summary_table_low_elo) < 20:\n",
    "    print(f\"Only {len(new_summary_table_low_elo)} games found with Elo < 1500.\")\n",
    "    sample_games = new_summary_table_low_elo\n",
    "else:\n",
    "    # Randomly select 20 games\n",
    "    sample_games = new_summary_table_low_elo.sample(n=20, random_state=42)\n",
    "\n",
    "# Step 2: Preprocess the selected games\n",
    "\n",
    "# Ensure the 'Opening' column is processed the same way as in training\n",
    "# If 'top_openings' was used to group less frequent openings under 'Other', apply the same here\n",
    "sample_games['Opening'] = sample_games['Opening'].apply(lambda x: x if x in top_openings else 'Other')\n",
    "\n",
    "# Process categorical features\n",
    "for col in categorical_features:\n",
    "    sample_games[col] = sample_games[col].astype('category')\n",
    "    # Ensure the categories match those in the training set\n",
    "    sample_games[col] = sample_games[col].cat.set_categories(new_summary_table[col].cat.categories)\n",
    "    # Fill NaN values with 'Unknown'\n",
    "    sample_games[col] = sample_games[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "sample_games[numerical_features] = sample_games[numerical_features].fillna(0)\n",
    "\n",
    "# Define features for prediction\n",
    "X_new = sample_games[categorical_features + numerical_features]\n",
    "\n",
    "# Step 3: Predict using the trained model\n",
    "y_new_pred = pipeline.predict(X_new)\n",
    "\n",
    "# Step 4: Output the predictions per game\n",
    "sample_games = sample_games.reset_index(drop=True)  # Reset index for clarity\n",
    "sample_games['Predicted_Elo'] = y_new_pred\n",
    "\n",
    "# Display the predictions per game\n",
    "print(\"Predictions for each game:\")\n",
    "print(sample_games[['GameID', 'Elo', 'Predicted_Elo']])\n",
    "\n",
    "# Step 5: Compute and display average, min, and max of the predictions\n",
    "average_pred = y_new_pred.mean()\n",
    "min_pred = y_new_pred.min()\n",
    "max_pred = y_new_pred.max()\n",
    "\n",
    "print(f\"\\nAverage Predicted Elo: {average_pred:.2f}\")\n",
    "print(f\"Minimum Predicted Elo: {min_pred:.2f}\")\n",
    "print(f\"Maximum Predicted Elo: {max_pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of Elo Distribution (Stratification Justification):\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(new_summary_table['Elo'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Elo Ratings')\n",
    "plt.xlabel('Elo')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Bar Chart\n",
    "top_features = coef_df.head(10)  # Top 10 features by absolute value\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_features['Feature'], top_features['AbsCoefficient'], color='orange')\n",
    "plt.title('Top 10 Features by Absolute Coefficient Value')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Absolute Coefficient')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot of Predicted vs Actual Elo:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, color='blue')\n",
    "plt.title('Predicted vs Actual Elo Ratings')\n",
    "plt.xlabel('Actual Elo')\n",
    "plt.ylabel('Predicted Elo')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Predicted vs. Actual Elo Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.title('Predicted vs. Actual Elo Ratings')\n",
    "plt.xlabel('Actual Elo Rating')\n",
    "plt.ylabel('Predicted Elo Rating')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot Residuals vs. Predicted Elo Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.hlines(0, y_pred.min(), y_pred.max(), colors='r', linestyles='dashed')\n",
    "plt.title('Residuals vs. Predicted Elo Ratings')\n",
    "plt.xlabel('Predicted Elo Rating')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical features into a single feature\n",
    "X_combined = X[numerical_features].sum(axis=1)\n",
    "# Reshape X_combined for model fitting\n",
    "X_combined_reshaped = X_combined.values.reshape(-1, 1)\n",
    "\n",
    "# Split the combined data\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n",
    "    X_combined_reshaped, y, test_size=0.2, random_state=40\n",
    ")\n",
    "\n",
    "# Create and train a new linear regression model\n",
    "model_combined = LinearRegression()\n",
    "model_combined.fit(X_train_combined, y_train_combined)\n",
    "# Predict using the combined feature\n",
    "y_pred_combined = model_combined.predict(X_test_combined)\n",
    "\n",
    "# Plot the data points and the regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test_combined, y_test_combined, alpha=0.5, label='Actual Data')\n",
    "plt.plot(X_test_combined, y_pred_combined, color='red', linewidth=2, label='Regression Line')\n",
    "plt.title('Elo Rating vs. Combined Numerical Feature')\n",
    "plt.xlabel('Sum of Numerical Features')\n",
    "plt.ylabel('Elo Rating')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating table based on train/test set\n",
    "\n",
    "For double-checking, we perform a train test split and compute the winning chance tables only on the training dataset. The results are near enough identical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winning_chances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_bins = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "\n",
    "df_train, df_test = winning_chances.train_test_split_games(df, train_size=0.8, random_state=42)\n",
    "\n",
    "table_train = winning_chances.compute_winning_chance_table(df_train)\n",
    "\n",
    "# Create summary tables for training and testing sets\n",
    "summary_table_train = winning_chances.create_summary_table(df_train, mistake_bins=mistake_bins, winning_chance_table=table_train)\n",
    "summary_table_test = winning_chances.create_summary_table(df_test, mistake_bins=mistake_bins, winning_chance_table=table_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the linear regression on the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 284.09\n",
      "R-squared Score (R²): nan\n",
      "Percentage of predictions within ±300 Elo: 100.00%\n",
      "\n",
      "Top 5 features by absolute coefficient value:\n",
      "                                        Feature  Coefficient\n",
      "29  Opening_Queen's pawn game, Krause variation  -668.680325\n",
      "42                               Opening_Vienna   625.007025\n",
      "11                         Opening_Four knights  -569.692350\n",
      "23                                 Opening_Pirc  -478.208058\n",
      "41                              Opening_Unknown   438.710561\n",
      "\n",
      "Coefficients for the mistake labels:\n",
      "     Feature  Coefficient\n",
      "59   (35,40]   177.481030\n",
      "63  (70,100]  -132.551046\n",
      "60   (40,50]  -121.685672\n",
      "56   (20,25]   -77.045770\n",
      "61   (50,60]    63.838408\n",
      "57   (25,30]    46.343011\n",
      "55   (15,20]   -19.601725\n",
      "58   (30,35]   -19.111015\n",
      "54   (10,15]   -15.096423\n",
      "53    (5,10]     8.223799\n",
      "62   (60,70]     0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorian/anaconda3/envs/guess_the_elo-env/lib/python3.12/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "numerical_features=['AWCL']\n",
    "categorical_features=['Opening', 'Result', 'TotalMovesInterval']\n",
    "total_moves_bins=[0, 40,  60,  80,  100, 120, np.inf] \n",
    "mistake_bins=[5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "Opening_number=70 \n",
    "Color_Player='White'\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Process the training summary table\n",
    "top_openings = summary_table_train['Opening'].value_counts().nlargest(Opening_number).index.tolist()\n",
    "summary_table_train['Opening'] = summary_table_train['Opening'].apply(lambda x: x if x in top_openings else 'Other')\n",
    "\n",
    "new_summary_table_train = summary_table_train[summary_table_train['Player'] == Color_Player].copy()\n",
    "\n",
    "# Define mistake labels based on columns after 'AWCL'\n",
    "start_index = new_summary_table_train.columns.get_loc('AWCL') + 1\n",
    "mistake_labels = list(new_summary_table_train.columns[start_index:])\n",
    "\n",
    "# Update numerical features to include mistake labels and 'AWCL'\n",
    "numerical_features = numerical_features + mistake_labels \n",
    "\n",
    "# Create 'TotalMovesInterval' using pd.cut\n",
    "total_moves_labels = [\n",
    "    f'({total_moves_bins[i]},{total_moves_bins[i+1]}]' if not np.isinf(total_moves_bins[i + 1]) else f'({total_moves_bins[i]},∞]'\n",
    "    for i in range(len(total_moves_bins) - 1)\n",
    "]\n",
    "\n",
    "# Create 'TotalMovesInterval' using pd.cut\n",
    "new_summary_table_train['TotalMovesInterval'] = pd.cut(\n",
    "    new_summary_table_train['TotalMoves'],\n",
    "    bins=total_moves_bins,\n",
    "    labels=total_moves_labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "new_summary_table_train = new_summary_table_train.dropna(subset=['Elo'])\n",
    "\n",
    "# Process categorical features in the training set\n",
    "for col in categorical_features:\n",
    "    new_summary_table_train[col] = new_summary_table_train[col].astype('category')\n",
    "    if 'Unknown' not in new_summary_table_train[col].cat.categories:\n",
    "        new_summary_table_train[col] = new_summary_table_train[col].cat.add_categories(['Unknown'])\n",
    "    new_summary_table_train[col] = new_summary_table_train[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "new_summary_table_train[numerical_features] = new_summary_table_train[numerical_features].fillna(0)\n",
    "\n",
    "# Define target variable and features for training\n",
    "y_train = new_summary_table_train['Elo']\n",
    "X_train = new_summary_table_train[categorical_features + numerical_features]\n",
    "\n",
    "# Process the testing summary table\n",
    "summary_table_test['Opening'] = summary_table_test['Opening'].apply(lambda x: x if x in top_openings else 'Other')\n",
    "\n",
    "new_summary_table_test = summary_table_test[summary_table_test['Player'] == Color_Player].copy()\n",
    "\n",
    "new_summary_table_test['TotalMovesInterval'] = pd.cut(\n",
    "    new_summary_table_test['TotalMoves'],\n",
    "    bins=total_moves_bins,\n",
    "    labels=total_moves_labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "new_summary_table_test = new_summary_table_test.dropna(subset=['Elo'])\n",
    "\n",
    "# Process categorical features in the testing set\n",
    "for col in categorical_features:\n",
    "    new_summary_table_test[col] = new_summary_table_test[col].astype('category')\n",
    "    # Ensure the categories match those in the training set\n",
    "    new_summary_table_test[col] = new_summary_table_test[col].cat.set_categories(new_summary_table_train[col].cat.categories)\n",
    "    new_summary_table_test[col] = new_summary_table_test[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "new_summary_table_test[numerical_features] = new_summary_table_test[numerical_features].fillna(0)\n",
    "\n",
    "# Define target variable and features for testing\n",
    "y_test = new_summary_table_test['Elo']\n",
    "X_test = new_summary_table_test[categorical_features + numerical_features]\n",
    "\n",
    "# Create a ColumnTransformer to apply OneHotEncoder to categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through numerical features unchanged\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared Score (R²): {r2:.2f}')\n",
    "\n",
    "# Calculate percentage of predictions within a threshold\n",
    "absolute_errors = np.abs(y_pred - y_test)\n",
    "threshold = 300\n",
    "within_threshold = np.sum(absolute_errors <= threshold)\n",
    "total_predictions = len(y_test)\n",
    "percentage_within_threshold = (within_threshold / total_predictions) * 100\n",
    "\n",
    "print(f\"Percentage of predictions within ±{threshold} Elo: {percentage_within_threshold:.2f}%\")\n",
    "\n",
    "# Get the names of the categorical features after one-hot encoding\n",
    "onehot_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine with numerical feature names\n",
    "all_feature_names = np.concatenate([onehot_feature_names, numerical_features])\n",
    "coefficients = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the coefficients by absolute value\n",
    "coef_df['AbsCoefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='AbsCoefficient', ascending=False)\n",
    "\n",
    "# Display the top 5 features with the highest absolute coefficients\n",
    "print(\"\\nTop 5 features by absolute coefficient value:\")\n",
    "print(coef_df[['Feature', 'Coefficient']].head(5))\n",
    "\n",
    "# Display the coefficients for the mistake labels\n",
    "mistake_coef_df = coef_df[coef_df['Feature'].isin(mistake_labels)]\n",
    "print(\"\\nCoefficients for the mistake labels:\")\n",
    "print(mistake_coef_df[['Feature', 'Coefficient']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
