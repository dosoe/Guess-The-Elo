{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "move_bins_for_WCL=np.arange(0,150,5)\n",
    "eval_bins=np.arange(-20.05,20.15,0.1)\n",
    "move_bins_for_eval=move_bins_for_WCL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Games, Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anal_games, functions_anal\n",
    "\n",
    "# Get the list of filenames matching the patterns\n",
    "filenames_15 = glob.glob(\"../Cleaned_Analyzed_Games/twic*_15_processed.csv\")\n",
    "filenames_16 = glob.glob(\"../Cleaned_Analyzed_Games/twic*_16_processed.csv\")\n",
    "\n",
    "# For dupes, use the bigger depth\n",
    "filenames_to_process=filenames_16\n",
    "for file in filenames_15:\n",
    "    if '_'.join(file.split('_')[:3])+'_16_processed.csv' in filenames_to_process:\n",
    "        continue\n",
    "    else:\n",
    "        filenames_to_process.append(file)\n",
    "\n",
    "outfile='../Cleaned_Analyzed_Games/all_games_cleaned.csv'\n",
    "\n",
    "# make list of games \n",
    "anal_games.process_all_files(outfile=outfile,filenames=filenames_to_process,functions=[functions_anal.MovesTotal,functions_anal.Cleanup,functions_anal.MovesBlack,functions_anal.MovesWhite],skip_if_processed=True,game_wise=True)\n",
    "\n",
    "df=pd.read_csv(outfile)\n",
    "\n",
    "df_train,df_test=train_test_split(df,test_size=0.2,random_state=100) # stratification with number of moves or elos doesn't work, as it needs at least two games for each unique value/combination of values. Binning doesn't help\n",
    "\n",
    "# save training set \n",
    "df_train.to_csv('../Cleaned_Analyzed_Games/all_games_cleaned_train.csv',index=False)\n",
    "df_test.to_csv('../Cleaned_Analyzed_Games/all_games_cleaned_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Winning, Losing and Drawing Chances from Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winning_chances_util\n",
    "\n",
    "# make bins for evaluations\n",
    "eval_bins=np.arange(-20.05,20.15,0.1)\n",
    "\n",
    "# make bins for moves\n",
    "move_bins_for_WCL=np.arange(0,150,5)\n",
    "\n",
    "# Compute winning chance tables from training data\n",
    "df=pd.read_csv('../Cleaned_Analyzed_Games/all_games_cleaned_train.csv')\n",
    "winning_chances_util.compute_winning_chance_table(df, intervals=eval_bins,movebins=move_bins_for_WCL,outdir='../winning_chances_tables')\n",
    "\n",
    "# Same, but only one move bin\n",
    "winning_chances_util.compute_winning_chance_table(df, intervals=eval_bins,movebins='all',outdir='../winning_chances_tables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Winning Chance Loss for each Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import concurrent.futures\n",
    "import winning_chances_util\n",
    "import anal_games\n",
    "\n",
    "df=pd.read_csv('../Cleaned_Analyzed_Games/all_games_cleaned_train.csv')\n",
    "\n",
    "process_by_move=True # do we want to have one winning table, or one for each move bracket?\n",
    "\n",
    "num_workers=15\n",
    "\n",
    "# for win chances binned by move\n",
    "move_bins_for_eval=move_bins_for_WCL\n",
    "wc_tables=winning_chances_util.read_winning_tables(dir='../winning_chances_tables/',movebins=move_bins_for_WCL)\n",
    "args = []\n",
    "i_process=0\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_train_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_train_'+str(move_bins_for_eval[-1])+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_test_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_test_'+str(move_bins_for_eval[-1])+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "# run it in parallel\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    tasks = []\n",
    "    for argument in args:\n",
    "        tasks.append(executor.submit(anal_games.process_game_list, argument[0],argument[1],argument[2],argument[3],argument[4]))\n",
    "\n",
    "# for winchances not binned by move\n",
    "\n",
    "movebins='all'\n",
    "\n",
    "wc_tables=winning_chances_util.read_winning_tables(dir='../winning_chances_tables/',movebins=movebins)\n",
    "args = []\n",
    "i_process=0\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_train_all_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],True,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_train_all_'+str(move_bins_for_eval[-1]+5)+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_test_all_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],True,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_test_all_'+str(move_bins_for_eval[-1]+5)+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    tasks = []\n",
    "    for argument in args:\n",
    "        tasks.append(executor.submit(anal_games.process_game_list, argument[0],argument[1],argument[2],argument[3],argument[4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape output tables to have tables by player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_WCL_table import WCL_by_player\n",
    "\n",
    "# for winchances calculated with binned moves\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=True)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=False,train=True)\n",
    "\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=False)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=False,train=False)\n",
    "\n",
    "\n",
    "# for winchances calculated with all moves\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=True)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=True,train=True)\n",
    "\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=False)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=True,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_mistakes_table import Mistakes_by_player\n",
    "\n",
    "# make mistake bins and mistake labels\n",
    "mistake_bins = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "# start move to count mistakes (counting starts at 0)\n",
    "move_start=3\n",
    "\n",
    "# for winchances calculated with binned moves\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=False,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=False,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=False,train=False,mistake_bins=mistake_bins,move_start=move_start)\n",
    "\n",
    "# for winchances calculated with all moves\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=True,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=False,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=True,train=False,mistake_bins=mistake_bins,move_start=move_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "all=False\n",
    "\n",
    "def get_filename(mv_start,mv_end,train,all):\n",
    "    filename='../Cleaned_Analyzed_Games/wcl_and_mistakes_'\n",
    "    if train:\n",
    "        filename+='train_'\n",
    "    else:\n",
    "        filename+='test_'\n",
    "    if all:\n",
    "        filename+='all_'\n",
    "    if mv_end==None:\n",
    "        filename+=str(mv_start)\n",
    "    else:\n",
    "        filename+=str(mv_start)+'-'+str(mv_end)\n",
    "    filename+='_by_player.csv'\n",
    "    return filename\n",
    "\n",
    "\n",
    "for i in [12]: #range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    mv_start=move_bins_for_eval[i]\n",
    "    mv_end=move_bins_for_eval[i+1]\n",
    "\n",
    "    filename=get_filename(mv_start,mv_end,train=True,all=all)\n",
    "\n",
    "    df=pd.read_csv(filename)\n",
    "\n",
    "    features=[]\n",
    "    for i in range(1,(mv_start//2)):\n",
    "        features.append('WCL_'+str(i))\n",
    "    \n",
    "    df_white=df.where(df['Player']=='White') # check which training games are in that file\n",
    "    df_white.dropna(how='any',inplace=True)\n",
    "\n",
    "    lr_white=LinearRegression()\n",
    "    \n",
    "    lr_white.fit(df_white[features],df_white['Elo'].astype(float))\n",
    "\n",
    "    filename_test=get_filename(mv_start,mv_end,train=False,all=all)\n",
    "\n",
    "    df_test=pd.read_csv(filename_test)\n",
    "\n",
    "    df_test_white=df.where(df_test['Player']=='White') # check which training games are in that file\n",
    "    df_test_white.dropna(how='any',inplace=True)\n",
    "\n",
    "    print('White Coeffs',lr_white.coef_)\n",
    "    print('White Intercept',lr_white.intercept_)\n",
    "\n",
    "    elo_pred_white=lr_white.predict(df_test_white[features])\n",
    "    residuals_white=df_test_white['Elo']-elo_pred_white\n",
    "    print('RMS White ', root_mean_squared_error(df_test_white['Elo'], elo_pred_white))\n",
    "\n",
    "    player_games=  df_test_white[(df_test_white['Elo'] >= 1400) & (df_test_white['Elo'] <= 1500)]\n",
    "\n",
    "    player_games = player_games.head(20)\n",
    "\n",
    "    out=lr_white.predict(player_games[features])\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(elo_pred_white,residuals_white,label='White',s=.1)\n",
    "    # plt.scatter(elo_pred_black,residuals_black,label='Black',s=.1)\n",
    "    plt.legend()\n",
    "    plt.xlim([1750,2500])\n",
    "    plt.savefig('Residuals_vs_predicted_'+str(mv_start)+'_'+str(mv_end)+'.png')\n",
    "\n",
    "    size_move_bins=5\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "[2268.11798967 2167.61384801 2172.24597165 2155.42403829 2232.12909506\n",
      " 2204.84716935 2333.79412945 2211.238637   2282.07036557 1804.9246347\n",
      " 2287.29170785 2237.74430132 2285.50147578 2228.71933708 2145.62424253\n",
      " 2249.21471697 2200.91591963 2155.40186094 2285.69892923 2259.87574242]\n",
      "svr\n",
      "[2283.25531481 2219.39499903 2224.53085701 2265.44032688 2255.69442236\n",
      " 2247.03757337 2328.09539918 2273.5913567  2292.7696265  2241.81807299\n",
      " 2269.99067321 2267.67289322 2277.40885216 2270.25960997 2226.22707886\n",
      " 2266.74431316 2240.21994016 2205.67656859 2277.24523468 2280.72756957]\n",
      "knr\n",
      "[2171.4 2213.3 2047.5 1921.7 2202.4 2097.7 2210.5 2025.8 2245.7 2121.9\n",
      " 2218.3 2095.7 2205.9 2122.2 2094.5 2028.1 1863.7 2149.8 2277.9 2164.4]\n",
      "rf\n",
      "[1746.13 1720.99 1735.54 1696.19 1651.68 1783.2  1829.9  1772.22 1815.43\n",
      " 1641.37 1738.33 1748.63 1776.02 1695.83 1650.47 1751.28 1767.35 1728.14\n",
      " 1800.29 1751.6 ]\n",
      "ab\n",
      "[2157.86634265 2076.7936898  2076.7936898  2000.19149909 2130.60107621\n",
      " 2170.25473794 2214.48110831 2064.67783308 2175.85085757 2230.38561035\n",
      " 2130.60107621 2053.19593558 2146.14545455 2076.7936898  2096.20826367\n",
      " 2000.19149909 2000.19149909 2068.34894466 2242.02831423 2191.23816443]\n",
      "gb\n",
      "[2225.17467005 2188.03935846 2194.52413459 2015.34321298 2162.31431409\n",
      " 2224.32985938 2350.0111087  2164.75714229 2258.73468749 2008.00715293\n",
      " 2188.74935255 2191.74262595 2268.46020013 2163.85266523 2135.23990633\n",
      " 2214.80058896 2141.59555479 2124.69613712 2235.16546491 2222.66790195]\n",
      "xbg\n",
      "[2095.4292 1734.598  1991.4404 1674.6747 1875.4893 1806.2885 2200.3555\n",
      " 2099.5938 2089.311  1485.3673 1980.8777 1862.7494 2183.1592 1942.0281\n",
      " 1889.4542 1886.8256 1762.0265 1597.1193 1786.4957 2125.5898]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': 74853.00226464237,\n",
       " 'svr': 77618.73119097012,\n",
       " 'knr': 67056.46594336766,\n",
       " 'rf': 10520.012804451848,\n",
       " 'ab': 85518.98150609506,\n",
       " 'gb': 69366.78211917859,\n",
       " 'xbg': 37752.86746873225}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models = {\n",
    "    'lr': LinearRegression(),\n",
    "    'svr': SVR(),\n",
    "    'knr': KNeighborsRegressor(n_neighbors=10),\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'ab': AdaBoostRegressor(),\n",
    "    'gb': GradientBoostingRegressor(),\n",
    "    'xbg': XGBRegressor()\n",
    "}\n",
    "\n",
    "all=False\n",
    "\n",
    "def get_filename(mv_start,mv_end,train,all):\n",
    "    filename='../Cleaned_Analyzed_Games/wcl_and_mistakes_'\n",
    "    if train:\n",
    "        filename+='train_'\n",
    "    else:\n",
    "        filename+='test_'\n",
    "    if all:\n",
    "        filename+='all_'\n",
    "    if mv_end==None:\n",
    "        filename+=str(mv_start)\n",
    "    else:\n",
    "        filename+=str(mv_start)+'-'+str(mv_end)\n",
    "    filename+='_by_player.csv'\n",
    "    return filename\n",
    "\n",
    "\n",
    "for i in [12]: #range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    mv_start=move_bins_for_eval[i]\n",
    "    mv_end=move_bins_for_eval[i+1]\n",
    "\n",
    "    filename=get_filename(mv_start,mv_end,train=True,all=all)\n",
    "\n",
    "    df=pd.read_csv(filename)\n",
    "\n",
    "    features=[]\n",
    "    for i in range(1,(mv_start//2)):\n",
    "        features.append('WCL_'+str(i))\n",
    "    target='Elo'\n",
    "    \n",
    "    df_white=df.where(df['Player']=='White') # check which training games are in that file\n",
    "    df_white.dropna(how='any',inplace=True)\n",
    "\n",
    "    filename_test=get_filename(mv_start,mv_end,train=False,all=all)\n",
    "\n",
    "    df_test=pd.read_csv(filename_test)\n",
    "\n",
    "    df_test_white=df.where(df_test['Player']=='White') # check which training games are in that file\n",
    "    df_test_white.dropna(how='any',inplace=True)\n",
    "\n",
    "    mses = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(df_white[features],df_white[target])\n",
    "        mses[name] = mean_squared_error(df_test_white[target], model.predict(df_test_white[features]))\n",
    "\n",
    "        player_games=  df_test_white[(df_test_white[target] >= 1400) & (df_test_white[target] <= 1500)]\n",
    "\n",
    "        player_games = player_games.head(20)\n",
    "\n",
    "        out=model.predict(player_games[features])\n",
    "\n",
    "        print(name)\n",
    "\n",
    "        print(out)\n",
    "\n",
    "mses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
