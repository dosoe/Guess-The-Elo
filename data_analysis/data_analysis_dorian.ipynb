{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "move_bins_for_WCL=np.arange(0,150,5)\n",
    "eval_bins=np.arange(-20.05,20.15,0.1)\n",
    "move_bins_for_eval=move_bins_for_WCL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Games, Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anal_games, functions_anal\n",
    "\n",
    "# Get the list of filenames matching the patterns\n",
    "filenames_15 = glob.glob(\"../Cleaned_Analyzed_Games/twic*_15_processed.csv\")\n",
    "filenames_16 = glob.glob(\"../Cleaned_Analyzed_Games/twic*_16_processed.csv\")\n",
    "\n",
    "# For dupes, use the bigger depth\n",
    "filenames_to_process=filenames_16\n",
    "for file in filenames_15:\n",
    "    if '_'.join(file.split('_')[:3])+'_16_processed.csv' in filenames_to_process:\n",
    "        continue\n",
    "    else:\n",
    "        filenames_to_process.append(file)\n",
    "\n",
    "outfile='../Cleaned_Analyzed_Games/all_games_cleaned.csv'\n",
    "\n",
    "# make list of games \n",
    "anal_games.process_all_files(outfile=outfile,filenames=filenames_to_process,functions=[functions_anal.MovesTotal,functions_anal.Cleanup,functions_anal.MovesBlack,functions_anal.MovesWhite],skip_if_processed=True,game_wise=True)\n",
    "\n",
    "df=pd.read_csv(outfile)\n",
    "\n",
    "df_train,df_test=train_test_split(df,test_size=0.2,random_state=100) # stratification with number of moves or elos doesn't work, as it needs at least two games for each unique value/combination of values. Binning doesn't help\n",
    "\n",
    "# save training set \n",
    "df_train.to_csv('../Cleaned_Analyzed_Games/all_games_cleaned_train.csv',index=False)\n",
    "df_test.to_csv('../Cleaned_Analyzed_Games/all_games_cleaned_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Winning, Losing and Drawing Chances from Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winning_chances_util\n",
    "\n",
    "# make bins for evaluations\n",
    "eval_bins=np.arange(-20.05,20.15,0.1)\n",
    "\n",
    "# make bins for moves\n",
    "move_bins_for_WCL=np.arange(0,150,5)\n",
    "\n",
    "# Compute winning chance tables from training data\n",
    "df=pd.read_csv('../Cleaned_Analyzed_Games/all_games_cleaned_train.csv')\n",
    "winning_chances_util.compute_winning_chance_table(df, intervals=eval_bins,movebins=move_bins_for_WCL,outdir='../winning_chances_tables')\n",
    "\n",
    "# Same, but only one move bin\n",
    "winning_chances_util.compute_winning_chance_table(df, intervals=eval_bins,movebins='all',outdir='../winning_chances_tables')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Winning Chance Loss for each Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import concurrent.futures\n",
    "import winning_chances_util\n",
    "import anal_games\n",
    "\n",
    "df=pd.read_csv('../Cleaned_Analyzed_Games/all_games_cleaned_train.csv')\n",
    "\n",
    "process_by_move=True # do we want to have one winning table, or one for each move bracket?\n",
    "\n",
    "num_workers=15\n",
    "\n",
    "# for win chances binned by move\n",
    "move_bins_for_eval=move_bins_for_WCL\n",
    "wc_tables=winning_chances_util.read_winning_tables(dir='../winning_chances_tables/',movebins=move_bins_for_WCL)\n",
    "args = []\n",
    "i_process=0\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_train_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_train_'+str(move_bins_for_eval[-1])+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_test_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_test_'+str(move_bins_for_eval[-1])+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "# run it in parallel\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    tasks = []\n",
    "    for argument in args:\n",
    "        tasks.append(executor.submit(anal_games.process_game_list, argument[0],argument[1],argument[2],argument[3],argument[4]))\n",
    "\n",
    "# for winchances not binned by move\n",
    "\n",
    "movebins='all'\n",
    "\n",
    "wc_tables=winning_chances_util.read_winning_tables(dir='../winning_chances_tables/',movebins=movebins)\n",
    "args = []\n",
    "i_process=0\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_train_all_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],True,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_train_all_'+str(move_bins_for_eval[-1]+5)+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "for i in range(len(move_bins_for_eval)-1):\n",
    "\n",
    "    \n",
    "    wc_tables_new=copy.deepcopy(wc_tables)\n",
    "\n",
    "    # bin moves\n",
    "    wc_tables_new['mv_min']=move_bins_for_eval[i]\n",
    "    wc_tables_new['mv_max']=move_bins_for_eval[i+1]\n",
    "\n",
    "    # only process games with moves in bin\n",
    "    df_moves=df.where(df['MovesAll']>=move_bins_for_eval[i])\n",
    "    df_moves=df_moves.where(df['MovesAll']<move_bins_for_eval[i+1])\n",
    "    df_moves.dropna(how='any',inplace=True)\n",
    "\n",
    "    if df_moves.shape[0]==0:\n",
    "        continue\n",
    "\n",
    "    args.append(('../Cleaned_Analyzed_Games/wcl_test_all_'+str(move_bins_for_eval[i])+'-'+str(move_bins_for_eval[i+1])+'.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],True,True))\n",
    "    i_process+=1\n",
    "\n",
    "wc_tables_new=copy.deepcopy(wc_tables)\n",
    "wc_tables_new['mv_min']=move_bins_for_eval[-1]\n",
    "wc_tables_new['mv_max']=100000\n",
    "args.append(('../Cleaned_Analyzed_Games/wcl_test_all_'+str(move_bins_for_eval[-1]+5)+'-.csv',df_moves,[(winning_chances_util.WinChanceIncrease,wc_tables_new)],False,True))\n",
    "i_process+=1\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    tasks = []\n",
    "    for argument in args:\n",
    "        tasks.append(executor.submit(anal_games.process_game_list, argument[0],argument[1],argument[2],argument[3],argument[4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape output tables to have tables by player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_WCL_table import WCL_by_player\n",
    "\n",
    "# for winchances calculated with binned moves\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=True)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=False,train=True)\n",
    "\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=False)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=False,train=False)\n",
    "\n",
    "\n",
    "# for winchances calculated with all moves\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=True)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=True,train=True)\n",
    "\n",
    "for i in move_bins_for_eval[-1]:\n",
    "\n",
    "    WCL_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=False)\n",
    "    \n",
    "WCL_by_player(move_bins_for_eval[-1],None,all=True,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_mistakes_table import Mistakes_by_player\n",
    "\n",
    "# make mistake bins and mistake labels\n",
    "mistake_bins = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "# start move to count mistakes (counting starts at 0)\n",
    "move_start=3\n",
    "\n",
    "# for winchances calculated with binned moves\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=False,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=False,train=False,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=False,train=False,mistake_bins=mistake_bins,move_start=move_start)\n",
    "\n",
    "# for winchances calculated with all moves\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=True,train=True,mistake_bins=mistake_bins,move_start=move_start)\n",
    "\n",
    "for i in range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    Mistakes_by_player(move_bins_for_eval[i],move_bins_for_eval[i+1],all=True,train=False,mistake_bins=mistake_bins,move_start=move_start)\n",
    "    \n",
    "Mistakes_by_player(move_bins_for_eval[-1],None,all=True,train=False,mistake_bins=mistake_bins,move_start=move_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "all=False\n",
    "\n",
    "def get_filename(mv_start,mv_end,train,all):\n",
    "    filename='../Cleaned_Analyzed_Games/wcl_and_mistakes_'\n",
    "    if train:\n",
    "        filename+='train_'\n",
    "    else:\n",
    "        filename+='test_'\n",
    "    if all:\n",
    "        filename+='all_'\n",
    "    if mv_end==None:\n",
    "        filename+=str(mv_start)\n",
    "    else:\n",
    "        filename+=str(mv_start)+'-'+str(mv_end)\n",
    "    filename+='_by_player.csv'\n",
    "    return filename\n",
    "\n",
    "\n",
    "for i in [12]: #range(len(move_bins_for_eval[:-1])):\n",
    "\n",
    "    mv_start=move_bins_for_eval[i]\n",
    "    mv_end=move_bins_for_eval[i+1]\n",
    "\n",
    "    filename=get_filename(mv_start,mv_end,train=True,all=all)\n",
    "\n",
    "    df=pd.read_csv(filename)\n",
    "\n",
    "    features=[]\n",
    "    for i in range(1,(mv_start//2)):\n",
    "        features.append('WCL_'+str(i))\n",
    "    \n",
    "    df_white=df.where(df['Player']=='White') # check which training games are in that file\n",
    "    df_white.dropna(how='any',inplace=True)\n",
    "\n",
    "    lr_white=LinearRegression()\n",
    "    \n",
    "    lr_white.fit(df_white[features],df_white['Elo'].astype(float))\n",
    "\n",
    "    filename_test=get_filename(mv_start,mv_end,train=False,all=all)\n",
    "\n",
    "    df_test=pd.read_csv(filename_test)\n",
    "\n",
    "    df_test_white=df.where(df_test['Player']=='White') # check which training games are in that file\n",
    "    df_test_white.dropna(how='any',inplace=True)\n",
    "\n",
    "    print('White Coeffs',lr_white.coef_)\n",
    "    print('White Intercept',lr_white.intercept_)\n",
    "\n",
    "    elo_pred_white=lr_white.predict(df_test_white[features])\n",
    "    residuals_white=df_test_white['Elo']-elo_pred_white\n",
    "    print('RMS White ', root_mean_squared_error(df_test_white['Elo'], elo_pred_white))\n",
    "\n",
    "    player_games=  df_test_white[(df_test_white['Elo'] >= 1400) & (df_test_white['Elo'] <= 1500)]\n",
    "\n",
    "    player_games = player_games.head(20)\n",
    "\n",
    "    out=lr_white.predict(player_games[features])\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(elo_pred_white,residuals_white,label='White',s=.1)\n",
    "    # plt.scatter(elo_pred_black,residuals_black,label='Black',s=.1)\n",
    "    plt.legend()\n",
    "    plt.xlim([1750,2500])\n",
    "    plt.savefig('Residuals_vs_predicted_'+str(mv_start)+'_'+str(mv_end)+'.png')\n",
    "\n",
    "    size_move_bins=5\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
