{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#df = pd.read_csv(\"../Analyzed_Games/twic1556_15_analyzed.csv\")\n",
    "#df=pd.read_csv(\"../Analyzed_Games/test2_15_analyzed.csv\")\n",
    "df= pd.read_csv(\"../Analyzed_Games/twic920_15_analyzed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data (use Dorian's cleaning function instead of this for better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games removed: 11\n"
     ]
    }
   ],
   "source": [
    "initial_game_count = df['GameID'].nunique()\n",
    "\n",
    "# Step 1: Identify GameIDs with valid 'Result'\n",
    "valid_result_games = df[df['Result'].isin(['1-0', '0-1', '1/2-1/2'])]['GameID'].unique()\n",
    "\n",
    "# Step 2: Identify GameIDs with no missing 'WhiteFideId' or 'BlackFideId'\n",
    "fide_valid_games = df.dropna(subset=['WhiteFideId', 'BlackFideId'])['GameID'].unique()\n",
    "\n",
    "# Step 3: Find the intersection of valid games\n",
    "valid_games = np.intersect1d(valid_result_games, fide_valid_games)\n",
    "\n",
    "# Step 4: Filter the DataFrame to include only valid games\n",
    "df_cleaned = df[df['GameID'].isin(valid_games)].copy()\n",
    "\n",
    "# Record the final number of unique games\n",
    "final_game_count = df_cleaned['GameID'].nunique()\n",
    "\n",
    "# Calculate the number of games removed\n",
    "removed_games = initial_game_count - final_game_count\n",
    "\n",
    "# Reset the index\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Create a mapping from old GameID to new sequential GameID\n",
    "unique_games = df_cleaned['GameID'].unique()\n",
    "game_id_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_games, start=1)}\n",
    "\n",
    "# Apply the mapping to fix 'GameID'\n",
    "df_cleaned['GameID'] = df_cleaned['GameID'].map(game_id_mapping)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file (optional)\n",
    "# df_cleaned.to_csv(\"../huge_analyzed_games/combined_analyzed_games_cleaned.csv\", index=False)\n",
    "\n",
    "# Print the number of games removed\n",
    "print(f\"Number of games removed: {removed_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Winning Chances column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Evaluation'] = df['Evaluation'].astype(str).str.strip()\n",
    "df['PlayerToMove'] = np.where(df['MoveNumber'] % 2 == 1, 'White', 'Black')\n",
    "\n",
    "# Function to convert 'Evaluation' to 'New_evaluations'\n",
    "def convert_evaluation(row):\n",
    "    eval_str = row['Evaluation']\n",
    "    \n",
    "    if eval_str in ['+M0', '-M0', 'M0']:\n",
    "        return 0.0  # Mate in 0 moves\n",
    "    elif eval_str.startswith('+M') or (eval_str.startswith('M') and not eval_str.startswith('-M')):\n",
    "        return 20.0  # White can mate\n",
    "    elif eval_str.startswith('-M'):\n",
    "        return -20.0  # Black can mate\n",
    "    else:\n",
    "        # Try to convert the evaluation to a float\n",
    "        try:\n",
    "            eval_float = float(eval_str)\n",
    "            return eval_float  # Numeric evaluation remains the same\n",
    "        except ValueError:\n",
    "            return np.nan  # Unable to parse evaluation\n",
    "\n",
    "# Apply the function to create 'New_evaluations' column\n",
    "df['New_evaluations'] = df.apply(convert_evaluation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0408163265306123,\n",
       " 1.0204081632653061,\n",
       " 96.93877551020408,\n",
       " 98,\n",
       " Outcome\n",
       " Loss    95\n",
       " Win      2\n",
       " Draw     1\n",
       " Name: count, dtype: int64]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map 'Result' to outcome from White's perspective\n",
    "def get_outcome(result):\n",
    "    if result == '1-0':\n",
    "        return 'Win'    # White won\n",
    "    elif result == '0-1':\n",
    "        return 'Loss'   # White lost\n",
    "    elif result == '1/2-1/2':\n",
    "        return 'Draw'   # Draw\n",
    "    else:\n",
    "        return None     # Exclude other results\n",
    "    \n",
    "    \n",
    "def calculate_chances(df, lower_eval, upper_eval):\n",
    "    # Filter positions where 'New_evaluations' is between lower_eval and upper_eval\n",
    "    positions_in_range = df[(df['New_evaluations'] >= lower_eval) & (df['New_evaluations'] <= upper_eval)].copy()\n",
    "    \n",
    "    # Get unique GameIDs where this occurs\n",
    "    games_in_range = positions_in_range['GameID'].unique()\n",
    "    \n",
    "    # Get the results of these games\n",
    "    game_results = df[df['GameID'].isin(games_in_range)][['GameID', 'Result']].drop_duplicates()\n",
    "    \n",
    "    # Apply the mapping\n",
    "    game_results['Outcome'] = game_results['Result'].apply(get_outcome)\n",
    "    \n",
    "    # Exclude games with 'Other' outcomes\n",
    "    valid_results = game_results.dropna(subset=['Outcome'])\n",
    "    \n",
    "    # Total number of valid games\n",
    "    total_valid_games = valid_results.shape[0]\n",
    "    outcome_counts=None\n",
    "    if total_valid_games == 0:\n",
    "        winning_chance = drawing_chance = losing_chance = 0.0\n",
    "    else:\n",
    "        # Count the number of games in each category\n",
    "        outcome_counts = valid_results['Outcome'].value_counts()\n",
    "        \n",
    "        # Calculate percentages\n",
    "        winning_chance = (outcome_counts.get('Win', 0) / total_valid_games) * 100\n",
    "        drawing_chance = (outcome_counts.get('Draw', 0) / total_valid_games) * 100\n",
    "        losing_chance = (outcome_counts.get('Loss', 0) / total_valid_games) * 100\n",
    "    \n",
    "    return [winning_chance, drawing_chance, losing_chance, total_valid_games,outcome_counts]\n",
    "\n",
    "\n",
    "calculate_chances(df,-21,-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=pd.read_csv(\"winning_chances_adjusted.csv\")\n",
    "intervals = np.arange(-21, 21.5, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "bin_labels = [f\"({intervals[i]}, {intervals[i+1]}]\" for i in range(len(intervals) - 1)]\n",
    "\n",
    "# Bin 'New_evaluations' in 'df' to create an 'Interval' column\n",
    "df['Interval'] = pd.cut(\n",
    "    df['New_evaluations'],\n",
    "    bins=intervals,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Merge 'df' with 'results_df' on 'Interval' to get 'WinningChance'\n",
    "df = df.merge(results_df[['Interval', 'WinningChance', \"LosingChance\"]], on='Interval', how='left')\n",
    "\n",
    "# Rename 'WinningChance' column to 'Winning_Chance' in 'df'\n",
    "df.rename(columns={'WinningChance': 'Winning_Chance'}, inplace=True)\n",
    "\n",
    "\n",
    "#df.to_csv(\"../huge_analyzed_games/combined_analyzed_15_16_winning_chances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the table (no need to run this yourselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df' is your DataFrame and 'calculate_chances' function is already defined\n",
    "\n",
    "# Define the intervals\n",
    "intervals = np.arange(-20.2, 20.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over intervals\n",
    "for i in range(len(intervals) - 1):\n",
    "    lower_eval = intervals[i]\n",
    "    upper_eval = intervals[i + 1]\n",
    "    \n",
    "    # Call the calculate_chances function\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games = calculate_chances(df, lower_eval, upper_eval)[:4]\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Interval': f\"({lower_eval}, {upper_eval}]\",\n",
    "        'LowerEval': lower_eval,\n",
    "        'UpperEval': upper_eval,\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Now, adjust the DataFrame to fill intervals with TotalGames == 0\n",
    "# Find the closest interval with TotalGames > 0 and copy its chances\n",
    "\n",
    "# Create a DataFrame of intervals with TotalGames > 0\n",
    "non_zero_df = results_df[results_df['TotalGames'] > 0].reset_index(drop=True)\n",
    "\n",
    "# Function to fill in chances for intervals with TotalGames == 0\n",
    "def fill_chances(row):\n",
    "    if row['TotalGames'] > 0:\n",
    "        # Keep original values\n",
    "        return row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "    else:\n",
    "        lower_eval = row['LowerEval']\n",
    "        # Compute absolute difference in LowerEval\n",
    "        diffs = (non_zero_df['LowerEval'] - lower_eval).abs()\n",
    "        min_idx = diffs.idxmin()\n",
    "        closest_row = non_zero_df.loc[min_idx]\n",
    "        return closest_row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "\n",
    "# Apply the function to fill in the missing chances\n",
    "filled_chances = results_df.apply(fill_chances, axis=1)\n",
    "\n",
    "# Assign the filled values back to the DataFrame\n",
    "results_df[['WinningChance', 'DrawingChance', 'LosingChance']] = filled_chances\n",
    "\n",
    "# Remove the 'LowerEval' and 'UpperEval' columns\n",
    "results_df = results_df.drop(columns=['LowerEval', 'UpperEval'])\n",
    "\n",
    "#results_df.to_csv('winning_chances.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the 'WinningChance' column to be monotonically increasing\n",
    "winning_chances = results_df['WinningChance'].values\n",
    "for i in range(1, len(winning_chances)):\n",
    "    if winning_chances[i] < winning_chances[i-1]:\n",
    "        winning_chances[i] = winning_chances[i-1]\n",
    "results_df['WinningChance'] = winning_chances\n",
    "\n",
    "# Adjust the 'LosingChance' column to be monotonically decreasing\n",
    "losing_chances = results_df['LosingChance'].values\n",
    "for i in range(len(losing_chances)-2, -1, -1):\n",
    "    if losing_chances[i] < losing_chances[i+1]:\n",
    "        losing_chances[i] = losing_chances[i+1]\n",
    "results_df['LosingChance'] = losing_chances\n",
    "\n",
    "# Save the modified DataFrame back to CSV\n",
    "results_df.to_csv('winning_chances_adjusted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
