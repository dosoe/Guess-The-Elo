{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#df = pd.read_csv(\"../Analyzed_Games/twic1556_15_analyzed.csv\")\n",
    "#df=pd.read_csv(\"../Analyzed_Games/test2_15_analyzed.csv\")\n",
    "#df= pd.read_csv(\"../Analyzed_Games/twic920_15_analyzed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data (use Dorian's cleaning function instead of this for better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games removed: 11\n"
     ]
    }
   ],
   "source": [
    "initial_game_count = df['GameID'].nunique()\n",
    "\n",
    "# Step 1: Identify GameIDs with valid 'Result'\n",
    "valid_result_games = df[df['Result'].isin(['1-0', '0-1', '1/2-1/2'])]['GameID'].unique()\n",
    "\n",
    "# Step 2: Identify GameIDs with no missing 'WhiteFideId' or 'BlackFideId'\n",
    "fide_valid_games = df.dropna(subset=['WhiteFideId', 'BlackFideId'])['GameID'].unique()\n",
    "\n",
    "# Step 3: Find the intersection of valid games\n",
    "valid_games = np.intersect1d(valid_result_games, fide_valid_games)\n",
    "\n",
    "# Step 4: Filter the DataFrame to include only valid games\n",
    "df_cleaned = df[df['GameID'].isin(valid_games)].copy()\n",
    "\n",
    "# Record the final number of unique games\n",
    "final_game_count = df_cleaned['GameID'].nunique()\n",
    "\n",
    "# Calculate the number of games removed\n",
    "removed_games = initial_game_count - final_game_count\n",
    "\n",
    "# Reset the index\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Create a mapping from old GameID to new sequential GameID\n",
    "unique_games = df_cleaned['GameID'].unique()\n",
    "game_id_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_games, start=1)}\n",
    "\n",
    "# Apply the mapping to fix 'GameID'\n",
    "df_cleaned['GameID'] = df_cleaned['GameID'].map(game_id_mapping)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file (optional)\n",
    "# df_cleaned.to_csv(\"../huge_analyzed_games/combined_analyzed_games_cleaned.csv\", index=False)\n",
    "\n",
    "# Print the number of games removed\n",
    "print(f\"Number of games removed: {removed_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Winning Chances column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Evaluation'] = df['Evaluation'].astype(str).str.strip()\n",
    "df['PlayerToMove'] = np.where(df['MoveNumber'] % 2 == 1, 'White', 'Black')\n",
    "\n",
    "# Function to convert 'Evaluation' to 'New_evaluations'\n",
    "def convert_evaluation(row):\n",
    "    eval_str = row['Evaluation']\n",
    "    \n",
    "    if eval_str in ['+M0', '-M0', 'M0']:\n",
    "        return 0.0  # Mate in 0 moves\n",
    "    elif eval_str.startswith('+M') or (eval_str.startswith('M') and not eval_str.startswith('-M')):\n",
    "        return 20.0  # White can mate\n",
    "    elif eval_str.startswith('-M'):\n",
    "        return -20.0  # Black can mate\n",
    "    else:\n",
    "        # Try to convert the evaluation to a float\n",
    "        try:\n",
    "            eval_float = float(eval_str)\n",
    "            return eval_float  # Numeric evaluation remains the same\n",
    "        except ValueError:\n",
    "            return np.nan  # Unable to parse evaluation\n",
    "\n",
    "# Apply the function to create 'New_evaluations' column\n",
    "df['New_evaluations'] = df.apply(convert_evaluation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0408163265306123,\n",
       " 1.0204081632653061,\n",
       " 96.93877551020408,\n",
       " 98,\n",
       " Outcome\n",
       " Loss    95\n",
       " Win      2\n",
       " Draw     1\n",
       " Name: count, dtype: int64]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map 'Result' to outcome from White's perspective\n",
    "def get_outcome(result):\n",
    "    if result == '1-0':\n",
    "        return 'Win'    # White won\n",
    "    elif result == '0-1':\n",
    "        return 'Loss'   # White lost\n",
    "    elif result == '1/2-1/2':\n",
    "        return 'Draw'   # Draw\n",
    "    else:\n",
    "        return None     # Exclude other results\n",
    "    \n",
    "    \n",
    "def calculate_chances(df, lower_eval, upper_eval):\n",
    "    # Filter positions where 'New_evaluations' is between lower_eval and upper_eval\n",
    "    positions_in_range = df[(df['New_evaluations'] >= lower_eval) & (df['New_evaluations'] <= upper_eval)].copy()\n",
    "    \n",
    "    # Get unique GameIDs where this occurs\n",
    "    games_in_range = positions_in_range['GameID'].unique()\n",
    "    \n",
    "    # Get the results of these games\n",
    "    game_results = df[df['GameID'].isin(games_in_range)][['GameID', 'Result']].drop_duplicates()\n",
    "    \n",
    "    # Apply the mapping\n",
    "    game_results['Outcome'] = game_results['Result'].apply(get_outcome)\n",
    "    \n",
    "    # Exclude games with 'Other' outcomes\n",
    "    valid_results = game_results.dropna(subset=['Outcome'])\n",
    "    \n",
    "    # Total number of valid games\n",
    "    total_valid_games = valid_results.shape[0]\n",
    "    outcome_counts=None\n",
    "    if total_valid_games == 0:\n",
    "        winning_chance = drawing_chance = losing_chance = 0.0\n",
    "    else:\n",
    "        # Count the number of games in each category\n",
    "        outcome_counts = valid_results['Outcome'].value_counts()\n",
    "        \n",
    "        # Calculate percentages\n",
    "        winning_chance = (outcome_counts.get('Win', 0) / total_valid_games) * 100\n",
    "        drawing_chance = (outcome_counts.get('Draw', 0) / total_valid_games) * 100\n",
    "        losing_chance = (outcome_counts.get('Loss', 0) / total_valid_games) * 100\n",
    "    \n",
    "    return [winning_chance, drawing_chance, losing_chance, total_valid_games,outcome_counts]\n",
    "\n",
    "\n",
    "calculate_chances(df,-21,-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=pd.read_csv(\"winning_chances_adjusted.csv\")\n",
    "intervals = np.arange(-21, 21.5, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "bin_labels = [f\"({intervals[i]}, {intervals[i+1]}]\" for i in range(len(intervals) - 1)]\n",
    "\n",
    "# Bin 'New_evaluations' in 'df' to create an 'Interval' column\n",
    "df['Interval'] = pd.cut(\n",
    "    df['New_evaluations'],\n",
    "    bins=intervals,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Merge 'df' with 'results_df' on 'Interval' to get 'WinningChance'\n",
    "df = df.merge(results_df[['Interval', 'WinningChance', \"LosingChance\"]], on='Interval', how='left')\n",
    "\n",
    "# Rename 'WinningChance' column to 'Winning_Chance' in 'df'\n",
    "df.rename(columns={'WinningChance': 'Winning_Chance'}, inplace=True)\n",
    "\n",
    "\n",
    "#df.to_csv(\"../huge_analyzed_games/combined_analyzed_15_16_winning_chances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Chances based on Move Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your 'get_outcome' function\n",
    "def get_outcome(result):\n",
    "    if result == '1-0':\n",
    "        return 'Win'    # White won\n",
    "    elif result == '0-1':\n",
    "        return 'Loss'   # White lost\n",
    "    elif result == '1/2-1/2':\n",
    "        return 'Draw'   # Draw\n",
    "    else:\n",
    "        return None     # Exclude other results\n",
    "    \n",
    "def calculate_chances(df, lower_eval, upper_eval, lower_move, upper_move):\n",
    "    # Filter positions where 'New_evaluations' is between lower_eval and upper_eval\n",
    "    # and 'MoveNumber' is between lower_move and upper_move\n",
    "    positions_in_range = df[\n",
    "        (df['Evaluation'] >= lower_eval) &\n",
    "        (df['Evaluation'] <= upper_eval) &\n",
    "        (df['MoveNumber'] >= lower_move) &\n",
    "        (df['MoveNumber'] <= upper_move)\n",
    "    ].copy()\n",
    "\n",
    "    # Get unique GameIDs where this occurs\n",
    "    games_in_range = positions_in_range['GameID'].unique()\n",
    "\n",
    "    # Get the results of these games, ensuring one entry per GameID\n",
    "    game_results = df[df['GameID'].isin(games_in_range)][['GameID', 'Result']].drop_duplicates(subset='GameID')\n",
    "\n",
    "    # Apply the mapping\n",
    "    game_results['Outcome'] = game_results['Result'].apply(get_outcome)\n",
    "\n",
    "    # Exclude games with 'Other' outcomes\n",
    "    valid_results = game_results.dropna(subset=['Outcome'])\n",
    "\n",
    "    # Total number of valid games\n",
    "    total_valid_games = valid_results.shape[0]\n",
    "\n",
    "    outcome_counts = None\n",
    "    if total_valid_games == 0:\n",
    "        winning_chance = drawing_chance = losing_chance = 0.0\n",
    "    else:\n",
    "        # Count the number of games in each category\n",
    "        outcome_counts = valid_results['Outcome'].value_counts()\n",
    "\n",
    "        # Calculate percentages\n",
    "        winning_chance = (outcome_counts.get('Win', 0) / total_valid_games) * 100\n",
    "        drawing_chance = (outcome_counts.get('Draw', 0) / total_valid_games) * 100\n",
    "        losing_chance = (outcome_counts.get('Loss', 0) / total_valid_games) * 100\n",
    "\n",
    "    return [winning_chance, drawing_chance, losing_chance, total_valid_games, outcome_counts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create move bins of 5 moves (assuming 'MoveNumber' increments by 1 per half-move)\n",
    "# So each bin will cover 10 half-moves (5 full moves)\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "# Define the maximum move number\n",
    "max_move_number = df['MoveNumber'].max()\n",
    "\n",
    "# Create move bins\n",
    "move_bins = []\n",
    "for i in range(0, int(max_move_number) + 10, 10):  # Increment by 10 half-moves\n",
    "    lower_move = i + 1  # Start from 1\n",
    "    upper_move = i + 10\n",
    "    move_bins.append((lower_move, upper_move))\n",
    "\n",
    "# Example evaluation interval\n",
    "lower_eval = 4\n",
    "upper_eval = 4.2\n",
    "\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over move bins and calculate chances\n",
    "for bin_index, (lower_move, upper_move) in enumerate(move_bins, start=1):\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games, _ = calculate_chances(\n",
    "        df, lower_eval, upper_eval, lower_move, upper_move\n",
    "    )\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'MoveBin': f\"Bin {bin_index} ({lower_move}-{upper_move})\",\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the table (no need to run this yourselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df' is your DataFrame and 'calculate_chances' function is already defined\n",
    "\n",
    "# Define the intervals\n",
    "intervals = np.arange(-20.2, 20.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over intervals\n",
    "for i in range(len(intervals) - 1):\n",
    "    lower_eval = intervals[i]\n",
    "    upper_eval = intervals[i + 1]\n",
    "    \n",
    "    # Call the calculate_chances function\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games = calculate_chances(df, lower_eval, upper_eval)[:4]\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Interval': f\"({lower_eval}, {upper_eval}]\",\n",
    "        'LowerEval': lower_eval,\n",
    "        'UpperEval': upper_eval,\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Now, adjust the DataFrame to fill intervals with TotalGames == 0\n",
    "# Find the closest interval with TotalGames > 0 and copy its chances\n",
    "\n",
    "# Create a DataFrame of intervals with TotalGames > 0\n",
    "non_zero_df = results_df[results_df['TotalGames'] > 0].reset_index(drop=True)\n",
    "\n",
    "# Function to fill in chances for intervals with TotalGames == 0\n",
    "def fill_chances(row):\n",
    "    if row['TotalGames'] > 0:\n",
    "        # Keep original values\n",
    "        return row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "    else:\n",
    "        lower_eval = row['LowerEval']\n",
    "        # Compute absolute difference in LowerEval\n",
    "        diffs = (non_zero_df['LowerEval'] - lower_eval).abs()\n",
    "        min_idx = diffs.idxmin()\n",
    "        closest_row = non_zero_df.loc[min_idx]\n",
    "        return closest_row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "\n",
    "# Apply the function to fill in the missing chances\n",
    "filled_chances = results_df.apply(fill_chances, axis=1)\n",
    "\n",
    "# Assign the filled values back to the DataFrame\n",
    "results_df[['WinningChance', 'DrawingChance', 'LosingChance']] = filled_chances\n",
    "\n",
    "# Remove the 'LowerEval' and 'UpperEval' columns\n",
    "results_df = results_df.drop(columns=['LowerEval', 'UpperEval'])\n",
    "\n",
    "#results_df.to_csv('winning_chances.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the 'WinningChance' column to be monotonically increasing\n",
    "winning_chances = results_df['WinningChance'].values\n",
    "for i in range(1, len(winning_chances)):\n",
    "    if winning_chances[i] < winning_chances[i-1]:\n",
    "        winning_chances[i] = winning_chances[i-1]\n",
    "results_df['WinningChance'] = winning_chances\n",
    "\n",
    "# Adjust the 'LosingChance' column to be monotonically decreasing\n",
    "losing_chances = results_df['LosingChance'].values\n",
    "for i in range(len(losing_chances)-2, -1, -1):\n",
    "    if losing_chances[i] < losing_chances[i+1]:\n",
    "        losing_chances[i] = losing_chances[i+1]\n",
    "results_df['LosingChance'] = losing_chances\n",
    "\n",
    "# Save the modified DataFrame back to CSV\n",
    "results_df.to_csv('winning_chances_adjusted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved winning chances table for all moves to winning_chances_all_moves.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame 'df' is loaded and contains the necessary columns\n",
    "\n",
    "# Define the evaluation intervals\n",
    "intervals = np.arange(-13, 13.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "# Set move range to cover all moves in the dataset\n",
    "lower_move = df['MoveNumber'].min()\n",
    "upper_move = df['MoveNumber'].max()\n",
    "\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over evaluation intervals\n",
    "for i in range(len(edges) - 1):\n",
    "    lower_eval = edges[i]\n",
    "    upper_eval = edges[i + 1]\n",
    "\n",
    "    # Call the calculate_chances function with move parameters covering all moves\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games, _ = calculate_chances(\n",
    "        df, lower_eval, upper_eval, lower_move, upper_move\n",
    "    )\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Interval': bin_labels[i],\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_filename = \"winning_chances_all_moves.csv\"\n",
    "results_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Saved winning chances table for all moves to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The tables based on move order (no need to run this yourselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "#df=pd.read_csv(\"../Cleaned_Analyzed_Games/twic1477_16_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved winning chances table for moves 1-20 to winning_chances_moves_1-20.csv\n",
      "Saved winning chances table for moves 21-40 to winning_chances_moves_21-40.csv\n",
      "Saved winning chances table for moves 41-60 to winning_chances_moves_41-60.csv\n",
      "Saved winning chances table for moves 61-80 to winning_chances_moves_61-80.csv\n",
      "Saved winning chances table for moves 81-100 to winning_chances_moves_81-100.csv\n",
      "Saved winning chances table for moves 101-120 to winning_chances_moves_101-120.csv\n",
      "Copied winning chances table for moves 121-140 from moves 101-120\n",
      "Copied winning chances table for moves 141-160 from moves 101-120\n",
      "Copied winning chances table for moves 161-180 from moves 101-120\n",
      "Copied winning chances table for moves 181-200 from moves 101-120\n",
      "Copied winning chances table for moves 201-220 from moves 101-120\n",
      "Copied winning chances table for moves 221-240 from moves 101-120\n",
      "Copied winning chances table for moves 241-260 from moves 101-120\n",
      "Copied winning chances table for moves 261-280 from moves 101-120\n",
      "Copied winning chances table for moves 281-300 from moves 101-120\n",
      "Copied winning chances table for moves 301-320 from moves 101-120\n",
      "Copied winning chances table for moves 321-340 from moves 101-120\n",
      "Copied winning chances table for moves 341-360 from moves 101-120\n",
      "Copied winning chances table for moves 361-380 from moves 101-120\n",
      "Copied winning chances table for moves 381-400 from moves 101-120\n",
      "Copied winning chances table for moves 401-420 from moves 101-120\n",
      "Copied winning chances table for moves 421-440 from moves 101-120\n",
      "Copied winning chances table for moves 441-460 from moves 101-120\n",
      "Copied winning chances table for moves 461-480 from moves 101-120\n",
      "Copied winning chances table for moves 481-500 from moves 101-120\n",
      "Copied winning chances table for moves 501-520 from moves 101-120\n",
      "Copied winning chances table for moves 521-540 from moves 101-120\n",
      "Copied winning chances table for moves 541-560 from moves 101-120\n",
      "Copied winning chances table for moves 561-580 from moves 101-120\n",
      "Copied winning chances table for moves 581-600 from moves 101-120\n",
      "Copied winning chances table for moves 601-620 from moves 101-120\n",
      "Copied winning chances table for moves 621-640 from moves 101-120\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../test_winning_chances_tables'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the move bins\n",
    "max_move_number = 120\n",
    "move_range = 20\n",
    "move_bins = []\n",
    "for i in range(0, max_move_number, move_range):\n",
    "    lower_move = i + 1\n",
    "    upper_move = i + move_range\n",
    "    move_bins.append((lower_move, upper_move))\n",
    "\n",
    "# Define the evaluation intervals\n",
    "intervals = np.arange(-13, 13.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "# Initialize variable to hold the reference table for moves 101-120\n",
    "reference_results_df = None\n",
    "\n",
    "# Loop over move bins up to 120\n",
    "for lower_move, upper_move in move_bins:\n",
    "    # Prepare a list to hold the results\n",
    "    results = []\n",
    "\n",
    "    # Loop over evaluation intervals\n",
    "    for i in range(len(edges) - 1):\n",
    "        lower_eval = edges[i]\n",
    "        upper_eval = edges[i + 1]\n",
    "\n",
    "        # Call the calculate_chances function with move bin parameters\n",
    "        winning_chance, drawing_chance, losing_chance, total_valid_games, _ = calculate_chances(\n",
    "            df, lower_eval, upper_eval, lower_move, upper_move\n",
    "        )\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Interval': bin_labels[i],\n",
    "            'WinningChance': winning_chance,\n",
    "            'DrawingChance': drawing_chance,\n",
    "            'LosingChance': losing_chance,\n",
    "            'TotalGames': total_valid_games,\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    move_bin_label = f\"{lower_move}-{upper_move}\"\n",
    "    output_filename = f\"winning_chances_moves_{move_bin_label}.csv\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Saved winning chances table for moves {lower_move}-{upper_move} to {output_filename}\")\n",
    "\n",
    "    # If this is the move bin for moves 101-120, save the results_df as the reference table\n",
    "    if lower_move == 101 and upper_move == 120:\n",
    "        reference_results_df = results_df.copy()\n",
    "\n",
    "# For move bins beyond 120, copy the table from moves 101-120\n",
    "max_move_number_in_df = df['MoveNumber'].max()\n",
    "additional_move_bins = []\n",
    "current_move = 120\n",
    "while current_move < max_move_number_in_df:\n",
    "    lower_move = current_move + 1\n",
    "    upper_move = current_move + move_range\n",
    "    additional_move_bins.append((lower_move, upper_move))\n",
    "    current_move += move_range\n",
    "\n",
    "# Copy the reference table to additional move bins\n",
    "if reference_results_df is not None:\n",
    "    for lower_move, upper_move in additional_move_bins:\n",
    "        # Save the reference DataFrame to a CSV file with the new move bin label\n",
    "        move_bin_label = f\"{lower_move}-{upper_move}\"\n",
    "        output_filename = f\"winning_chances_moves_{move_bin_label}.csv\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        reference_results_df.to_csv(output_path, index=False)\n",
    "        print(f\"Copied winning chances table for moves {lower_move}-{upper_move} from moves 101-120\")\n",
    "else:\n",
    "    print(\"Reference table for moves 101-120 is not available. Cannot copy to later move bins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1174923"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.GameID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Winning Chances Column based on multiple tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df= pd.read_csv(\"../Cleaned_Analyzed_Games/twic920_15_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume 'df' is your DataFrame with the analyzed games\n",
    "\n",
    "# Read and combine all winning chances tables\n",
    "winning_chances_tables = []\n",
    "for filename in glob.glob('../winning_chances_tables/winning_chances_moves_*.csv'):\n",
    "    # Extract the move bin from the filename\n",
    "    basename = os.path.basename(filename)\n",
    "    match = re.match(r'winning_chances_moves_(\\d+)-(\\d+)\\.csv', basename)\n",
    "    if match:\n",
    "        lower_move = int(match.group(1))\n",
    "        upper_move = int(match.group(2))\n",
    "        move_bin_label = f\"{lower_move}-{upper_move}\"\n",
    "        # Read the table\n",
    "        results_df = pd.read_csv(filename)\n",
    "        # Add the 'MoveBin' column\n",
    "        results_df['MoveBin'] = move_bin_label\n",
    "        # Append to the list\n",
    "        winning_chances_tables.append(results_df)\n",
    "\n",
    "# Combine all the winning chances tables\n",
    "winning_chances_combined = pd.concat(winning_chances_tables, ignore_index=True)\n",
    "\n",
    "# Prepare the main DataFrame 'df'\n",
    "\n",
    "# Ensure 'MoveNumber' is numeric\n",
    "df['MoveNumber'] = pd.to_numeric(df['MoveNumber'], errors='coerce')\n",
    "\n",
    "# Define the move bins as in the winning chances tables\n",
    "max_move_number = df['MoveNumber'].max()\n",
    "bin_size = 10  # 10 half-moves per bin (5 full moves)\n",
    "\n",
    "# Create edges for the bins\n",
    "edges = list(range(1, int(max_move_number) + bin_size + 1, bin_size))\n",
    "labels = [f\"{edges[i]}-{edges[i+1]-1}\" for i in range(len(edges)-1)]\n",
    "\n",
    "# Assign 'MoveBin' labels to 'MoveNumber' in df\n",
    "df['MoveBin'] = pd.cut(\n",
    "    df['MoveNumber'],\n",
    "    bins=edges,\n",
    "    labels=labels,\n",
    "    right=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Define evaluation intervals matching those in the winning chances tables\n",
    "intervals = np.arange(-20.2, 20.2 + 0.2, 0.2)  # Include upper limit\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "bin_labels = [f\"({intervals[i]}, {intervals[i+1]}]\" for i in range(len(intervals) - 1)]\n",
    "\n",
    "# Bin 'New_evaluations' in 'df' to create an 'Interval' column\n",
    "df['Interval'] = pd.cut(\n",
    "    df['Evaluation'],\n",
    "    bins=intervals,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Ensure 'MoveBin' and 'Interval' are strings for consistent merging\n",
    "df['MoveBin'] = df['MoveBin'].astype(str)\n",
    "df['Interval'] = df['Interval'].astype(str)\n",
    "winning_chances_combined['MoveBin'] = winning_chances_combined['MoveBin'].astype(str)\n",
    "winning_chances_combined['Interval'] = winning_chances_combined['Interval'].astype(str)\n",
    "\n",
    "# Merge 'df' with 'winning_chances_combined' on 'MoveBin' and 'Interval' to get 'WinningChance' and 'LosingChance'\n",
    "df = df.merge(\n",
    "    winning_chances_combined[['MoveBin', 'Interval', 'WinningChance', 'LosingChance', 'TotalGames']],\n",
    "    on=['MoveBin', 'Interval'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now 'df' has the 'Winning_Chance' and 'LosingChance' columns added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WCL'] = df.groupby('GameID')['WinningChance'].diff().abs()\n",
    "df['LCL'] = df.groupby('GameID')['LosingChance'].diff().abs()\n",
    "df.loc[df['MoveNumber'] % 2 == 0, 'WCL'] = None\n",
    "df.loc[df['MoveNumber'] % 2 != 0, 'LCL'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Winning Chances Column based on ONE table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df= pd.read_csv(\"../Cleaned_Analyzed_Games/twic920_15_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Read the 'winning_chances_all_moves.csv' Table\n",
    "results_df = pd.read_csv('winning_chances_all_moves.csv')\n",
    "\n",
    "# Step 2: Define Evaluation Intervals and Bin Labels\n",
    "# The intervals and bin labels should match those used when creating 'winning_chances_all_moves.csv'\n",
    "\n",
    "# Recreate the edges and bin labels\n",
    "intervals = np.arange(-13, 13.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "# Ensure that the bin labels in 'results_df' match the ones we're creating\n",
    "# This is important for a correct merge\n",
    "results_df['Interval'] = results_df['Interval'].astype(str)\n",
    "bin_labels = [str(label) for label in bin_labels]\n",
    "\n",
    "# Step 3: Bin the 'Evaluation' Values in 'df' to Create an 'Interval' Column\n",
    "# Assuming 'df' is your analyzed chess DataFrame and 'Evaluation' column exists\n",
    "df['Interval'] = pd.cut(\n",
    "    df['Evaluation'],\n",
    "    bins=edges,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Step 4: Merge 'df' with 'results_df' on 'Interval'\n",
    "# Select the columns to merge\n",
    "columns_to_merge = ['Interval', 'WinningChance', 'LosingChance', 'TotalGames']\n",
    "\n",
    "# Ensure 'Interval' in 'df' is of type string\n",
    "df['Interval'] = df['Interval'].astype(str)\n",
    "\n",
    "# Perform the merge\n",
    "df = df.merge(\n",
    "    results_df[columns_to_merge],\n",
    "    on='Interval',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now 'df' has the new columns added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WCL'] = df.groupby('GameID')['WinningChance'].diff().abs()\n",
    "df['LCL'] = df.groupby('GameID')['LosingChance'].diff().abs()\n",
    "df.loc[df['MoveNumber'] % 2 == 0, 'WCL'] = None\n",
    "df.loc[df['MoveNumber'] % 2 != 0, 'LCL'] = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
