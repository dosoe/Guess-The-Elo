{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#df = pd.read_csv(\"../Analyzed_Games/twic1556_15_analyzed.csv\")\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "#df= pd.read_csv(\"../Analyzed_Games/twic920_15_analyzed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data (use Dorian's cleaning function instead of this for better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_game_count = df['GameID'].nunique()\n",
    "\n",
    "# Step 1: Identify GameIDs with valid 'Result'\n",
    "valid_result_games = df[df['Result'].isin(['1-0', '0-1', '1/2-1/2'])]['GameID'].unique()\n",
    "\n",
    "# Step 2: Identify GameIDs with no missing 'WhiteFideId' or 'BlackFideId'\n",
    "fide_valid_games = df.dropna(subset=['WhiteFideId', 'BlackFideId'])['GameID'].unique()\n",
    "\n",
    "# Step 3: Find the intersection of valid games\n",
    "valid_games = np.intersect1d(valid_result_games, fide_valid_games)\n",
    "\n",
    "# Step 4: Filter the DataFrame to include only valid games\n",
    "df_cleaned = df[df['GameID'].isin(valid_games)].copy()\n",
    "\n",
    "# Record the final number of unique games\n",
    "final_game_count = df_cleaned['GameID'].nunique()\n",
    "\n",
    "# Calculate the number of games removed\n",
    "removed_games = initial_game_count - final_game_count\n",
    "\n",
    "# Reset the index\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Create a mapping from old GameID to new sequential GameID\n",
    "unique_games = df_cleaned['GameID'].unique()\n",
    "game_id_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_games, start=1)}\n",
    "\n",
    "# Apply the mapping to fix 'GameID'\n",
    "df_cleaned['GameID'] = df_cleaned['GameID'].map(game_id_mapping)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file (optional)\n",
    "# df_cleaned.to_csv(\"../huge_analyzed_games/combined_analyzed_games_cleaned.csv\", index=False)\n",
    "\n",
    "# Print the number of games removed\n",
    "print(f\"Number of games removed: {removed_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Winning Chances column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Evaluation'] = df['Evaluation'].astype(str).str.strip()\n",
    "df['PlayerToMove'] = np.where(df['MoveNumber'] % 2 == 1, 'White', 'Black')\n",
    "\n",
    "# Function to convert 'Evaluation' to 'New_evaluations'\n",
    "def convert_evaluation(row):\n",
    "    eval_str = row['Evaluation']\n",
    "    \n",
    "    if eval_str in ['+M0', '-M0', 'M0']:\n",
    "        return 0.0  # Mate in 0 moves\n",
    "    elif eval_str.startswith('+M') or (eval_str.startswith('M') and not eval_str.startswith('-M')):\n",
    "        return 20.0  # White can mate\n",
    "    elif eval_str.startswith('-M'):\n",
    "        return -20.0  # Black can mate\n",
    "    else:\n",
    "        # Try to convert the evaluation to a float\n",
    "        try:\n",
    "            eval_float = float(eval_str)\n",
    "            return eval_float  # Numeric evaluation remains the same\n",
    "        except ValueError:\n",
    "            return np.nan  # Unable to parse evaluation\n",
    "\n",
    "# Apply the function to create 'New_evaluations' column\n",
    "df['New_evaluations'] = df.apply(convert_evaluation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Result' to outcome from White's perspective\n",
    "def get_outcome(result):\n",
    "    if result == '1-0':\n",
    "        return 'Win'    # White won\n",
    "    elif result == '0-1':\n",
    "        return 'Loss'   # White lost\n",
    "    elif result == '1/2-1/2':\n",
    "        return 'Draw'   # Draw\n",
    "    else:\n",
    "        return None     # Exclude other results\n",
    "    \n",
    "    \n",
    "def calculate_chances(df, lower_eval, upper_eval):\n",
    "    # Filter positions where 'New_evaluations' is between lower_eval and upper_eval\n",
    "    positions_in_range = df[(df['New_evaluations'] >= lower_eval) & (df['New_evaluations'] <= upper_eval)].copy()\n",
    "    \n",
    "    # Get unique GameIDs where this occurs\n",
    "    games_in_range = positions_in_range['GameID'].unique()\n",
    "    \n",
    "    # Get the results of these games\n",
    "    game_results = df[df['GameID'].isin(games_in_range)][['GameID', 'Result']].drop_duplicates()\n",
    "    \n",
    "    # Apply the mapping\n",
    "    game_results['Outcome'] = game_results['Result'].apply(get_outcome)\n",
    "    \n",
    "    # Exclude games with 'Other' outcomes\n",
    "    valid_results = game_results.dropna(subset=['Outcome'])\n",
    "    \n",
    "    # Total number of valid games\n",
    "    total_valid_games = valid_results.shape[0]\n",
    "    outcome_counts=None\n",
    "    if total_valid_games == 0:\n",
    "        winning_chance = drawing_chance = losing_chance = 0.0\n",
    "    else:\n",
    "        # Count the number of games in each category\n",
    "        outcome_counts = valid_results['Outcome'].value_counts()\n",
    "        \n",
    "        # Calculate percentages\n",
    "        winning_chance = (outcome_counts.get('Win', 0) / total_valid_games) * 100\n",
    "        drawing_chance = (outcome_counts.get('Draw', 0) / total_valid_games) * 100\n",
    "        losing_chance = (outcome_counts.get('Loss', 0) / total_valid_games) * 100\n",
    "    \n",
    "    return [winning_chance, drawing_chance, losing_chance, total_valid_games,outcome_counts]\n",
    "\n",
    "\n",
    "calculate_chances(df,-21,-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=pd.read_csv(\"winning_chances_adjusted.csv\")\n",
    "intervals = np.arange(-21, 21.5, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "bin_labels = [f\"({intervals[i]}, {intervals[i+1]}]\" for i in range(len(intervals) - 1)]\n",
    "\n",
    "# Bin 'New_evaluations' in 'df' to create an 'Interval' column\n",
    "df['Interval'] = pd.cut(\n",
    "    df['New_evaluations'],\n",
    "    bins=intervals,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Merge 'df' with 'results_df' on 'Interval' to get 'WinningChance'\n",
    "df = df.merge(results_df[['Interval', 'WinningChance', \"LosingChance\"]], on='Interval', how='left')\n",
    "\n",
    "# Rename 'WinningChance' column to 'Winning_Chance' in 'df'\n",
    "df.rename(columns={'WinningChance': 'Winning_Chance'}, inplace=True)\n",
    "\n",
    "\n",
    "#df.to_csv(\"../huge_analyzed_games/combined_analyzed_15_16_winning_chances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Chances based on Move Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your 'get_outcome' function\n",
    "def get_outcome(result):\n",
    "    if result == '1-0':\n",
    "        return 'Win'    # White won\n",
    "    elif result == '0-1':\n",
    "        return 'Loss'   # White lost\n",
    "    elif result == '1/2-1/2':\n",
    "        return 'Draw'   # Draw\n",
    "    else:\n",
    "        return None     # Exclude other results\n",
    "    \n",
    "def calculate_chances(df, lower_eval, upper_eval, lower_move, upper_move):\n",
    "    # Filter positions where 'New_evaluations' is between lower_eval and upper_eval\n",
    "    # and 'MoveNumber' is between lower_move and upper_move\n",
    "    positions_in_range = df[\n",
    "        (df['Evaluation'] >= lower_eval) &\n",
    "        (df['Evaluation'] <= upper_eval) &\n",
    "        (df['MoveNumber'] >= lower_move) &\n",
    "        (df['MoveNumber'] <= upper_move)\n",
    "    ].copy()\n",
    "\n",
    "    # Get unique GameIDs where this occurs\n",
    "    games_in_range = positions_in_range['GameID'].unique()\n",
    "\n",
    "    # Get the results of these games, ensuring one entry per GameID\n",
    "    game_results = df[df['GameID'].isin(games_in_range)][['GameID', 'Result']].drop_duplicates(subset='GameID')\n",
    "\n",
    "    # Apply the mapping\n",
    "    game_results['Outcome'] = game_results['Result'].apply(get_outcome)\n",
    "\n",
    "    # Exclude games with 'Other' outcomes\n",
    "    valid_results = game_results.dropna(subset=['Outcome'])\n",
    "\n",
    "    # Total number of valid games\n",
    "    total_valid_games = valid_results.shape[0]\n",
    "\n",
    "    outcome_counts = None\n",
    "    if total_valid_games == 0:\n",
    "        winning_chance = drawing_chance = losing_chance = 0.0\n",
    "    else:\n",
    "        # Count the number of games in each category\n",
    "        outcome_counts = valid_results['Outcome'].value_counts()\n",
    "\n",
    "        # Calculate percentages\n",
    "        winning_chance = (outcome_counts.get('Win', 0) / total_valid_games) * 100\n",
    "        drawing_chance = (outcome_counts.get('Draw', 0) / total_valid_games) * 100\n",
    "        losing_chance = (outcome_counts.get('Loss', 0) / total_valid_games) * 100\n",
    "\n",
    "    return [winning_chance, drawing_chance, losing_chance, total_valid_games, outcome_counts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now, create move bins of 5 moves (assuming 'MoveNumber' increments by 1 per half-move)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# So each bin will cover 10 half-moves (5 full moves)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../huge_analyzed_games/combined_analyzed_games.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define the maximum move number\u001b[39;00m\n\u001b[1;32m      5\u001b[0m max_move_number \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoveNumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/anaconda3/envs/guess_the_elo-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/guess_the_elo-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/envs/guess_the_elo-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/guess_the_elo-env/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now, create move bins of 5 moves (assuming 'MoveNumber' increments by 1 per half-move)\n",
    "# So each bin will cover 10 half-moves (5 full moves)\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "# Define the maximum move number\n",
    "max_move_number = df['MoveNumber'].max()\n",
    "\n",
    "# Create move bins\n",
    "move_bins = []\n",
    "for i in range(0, int(max_move_number) + 10, 10):  # Increment by 10 half-moves\n",
    "    lower_move = i + 1  # Start from 1\n",
    "    upper_move = i + 10\n",
    "    move_bins.append((lower_move, upper_move))\n",
    "\n",
    "# Example evaluation interval\n",
    "lower_eval = 4\n",
    "upper_eval = 4.2\n",
    "\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over move bins and calculate chances\n",
    "for bin_index, (lower_move, upper_move) in enumerate(move_bins, start=1):\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games, _ = calculate_chances(\n",
    "        df, lower_eval, upper_eval, lower_move, upper_move\n",
    "    )\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'MoveBin': f\"Bin {bin_index} ({lower_move}-{upper_move})\",\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the table (no need to run this yourselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df' is your DataFrame and 'calculate_chances' function is already defined\n",
    "\n",
    "# Define the intervals\n",
    "intervals = np.arange(-20.2, 20.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over intervals\n",
    "for i in range(len(intervals) - 1):\n",
    "    lower_eval = intervals[i]\n",
    "    upper_eval = intervals[i + 1]\n",
    "    \n",
    "    # Call the calculate_chances function\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games = calculate_chances(df, lower_eval, upper_eval)[:4]\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Interval': f\"({lower_eval}, {upper_eval}]\",\n",
    "        'LowerEval': lower_eval,\n",
    "        'UpperEval': upper_eval,\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Now, adjust the DataFrame to fill intervals with TotalGames == 0\n",
    "# Find the closest interval with TotalGames > 0 and copy its chances\n",
    "\n",
    "# Create a DataFrame of intervals with TotalGames > 0\n",
    "non_zero_df = results_df[results_df['TotalGames'] > 0].reset_index(drop=True)\n",
    "\n",
    "# Function to fill in chances for intervals with TotalGames == 0\n",
    "def fill_chances(row):\n",
    "    if row['TotalGames'] > 0:\n",
    "        # Keep original values\n",
    "        return row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "    else:\n",
    "        lower_eval = row['LowerEval']\n",
    "        # Compute absolute difference in LowerEval\n",
    "        diffs = (non_zero_df['LowerEval'] - lower_eval).abs()\n",
    "        min_idx = diffs.idxmin()\n",
    "        closest_row = non_zero_df.loc[min_idx]\n",
    "        return closest_row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "\n",
    "# Apply the function to fill in the missing chances\n",
    "filled_chances = results_df.apply(fill_chances, axis=1)\n",
    "\n",
    "# Assign the filled values back to the DataFrame\n",
    "results_df[['WinningChance', 'DrawingChance', 'LosingChance']] = filled_chances\n",
    "\n",
    "# Remove the 'LowerEval' and 'UpperEval' columns\n",
    "results_df = results_df.drop(columns=['LowerEval', 'UpperEval'])\n",
    "\n",
    "#results_df.to_csv('winning_chances.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the 'WinningChance' column to be monotonically increasing\n",
    "winning_chances = results_df['WinningChance'].values\n",
    "for i in range(1, len(winning_chances)):\n",
    "    if winning_chances[i] < winning_chances[i-1]:\n",
    "        winning_chances[i] = winning_chances[i-1]\n",
    "results_df['WinningChance'] = winning_chances\n",
    "\n",
    "# Adjust the 'LosingChance' column to be monotonically decreasing\n",
    "losing_chances = results_df['LosingChance'].values\n",
    "for i in range(len(losing_chances)-2, -1, -1):\n",
    "    if losing_chances[i] < losing_chances[i+1]:\n",
    "        losing_chances[i] = losing_chances[i+1]\n",
    "results_df['LosingChance'] = losing_chances\n",
    "\n",
    "# Save the modified DataFrame back to CSV\n",
    "results_df.to_csv('winning_chances_adjusted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame 'df' is loaded and contains the necessary columns\n",
    "\n",
    "# Define the evaluation intervals\n",
    "intervals = np.arange(-13, 13.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "# Set move range to cover all moves in the dataset\n",
    "lower_move = df['MoveNumber'].min()\n",
    "upper_move = df['MoveNumber'].max()\n",
    "\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over evaluation intervals\n",
    "for i in range(len(edges) - 1):\n",
    "    lower_eval = edges[i]\n",
    "    upper_eval = edges[i + 1]\n",
    "\n",
    "    # Call the calculate_chances function with move parameters covering all moves\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games, _ = calculate_chances(\n",
    "        df, lower_eval, upper_eval, lower_move, upper_move\n",
    "    )\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Interval': bin_labels[i],\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_filename = \"winning_chances_all_moves.csv\"\n",
    "results_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Saved winning chances table for all moves to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The tables based on move order (no need to run this yourselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "#df=pd.read_csv(\"../Cleaned_Analyzed_Games/twic1477_16_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../test_winning_chances_tables'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the move bins\n",
    "max_move_number = 120\n",
    "move_range = 20\n",
    "move_bins = []\n",
    "for i in range(0, max_move_number, move_range):\n",
    "    lower_move = i + 1\n",
    "    upper_move = i + move_range\n",
    "    move_bins.append((lower_move, upper_move))\n",
    "\n",
    "# Define the evaluation intervals\n",
    "intervals = np.arange(-13, 13.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "# Initialize variable to hold the reference table for moves 101-120\n",
    "reference_results_df = None\n",
    "\n",
    "# Loop over move bins up to 120\n",
    "for lower_move, upper_move in move_bins:\n",
    "    # Prepare a list to hold the results\n",
    "    results = []\n",
    "\n",
    "    # Loop over evaluation intervals\n",
    "    for i in range(len(edges) - 1):\n",
    "        lower_eval = edges[i]\n",
    "        upper_eval = edges[i + 1]\n",
    "\n",
    "        # Call the calculate_chances function with move bin parameters\n",
    "        winning_chance, drawing_chance, losing_chance, total_valid_games, _ = calculate_chances(\n",
    "            df, lower_eval, upper_eval, lower_move, upper_move\n",
    "        )\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Interval': bin_labels[i],\n",
    "            'WinningChance': winning_chance,\n",
    "            'DrawingChance': drawing_chance,\n",
    "            'LosingChance': losing_chance,\n",
    "            'TotalGames': total_valid_games,\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    move_bin_label = f\"{lower_move}-{upper_move}\"\n",
    "    output_filename = f\"winning_chances_moves_{move_bin_label}.csv\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Saved winning chances table for moves {lower_move}-{upper_move} to {output_filename}\")\n",
    "\n",
    "    # If this is the move bin for moves 101-120, save the results_df as the reference table\n",
    "    if lower_move == 101 and upper_move == 120:\n",
    "        reference_results_df = results_df.copy()\n",
    "\n",
    "# For move bins beyond 120, copy the table from moves 101-120\n",
    "max_move_number_in_df = df['MoveNumber'].max()\n",
    "additional_move_bins = []\n",
    "current_move = 120\n",
    "while current_move < max_move_number_in_df:\n",
    "    lower_move = current_move + 1\n",
    "    upper_move = current_move + move_range\n",
    "    additional_move_bins.append((lower_move, upper_move))\n",
    "    current_move += move_range\n",
    "\n",
    "# Copy the reference table to additional move bins\n",
    "if reference_results_df is not None:\n",
    "    for lower_move, upper_move in additional_move_bins:\n",
    "        # Save the reference DataFrame to a CSV file with the new move bin label\n",
    "        move_bin_label = f\"{lower_move}-{upper_move}\"\n",
    "        output_filename = f\"winning_chances_moves_{move_bin_label}.csv\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        reference_results_df.to_csv(output_path, index=False)\n",
    "        print(f\"Copied winning chances table for moves {lower_move}-{upper_move} from moves 101-120\")\n",
    "else:\n",
    "    print(\"Reference table for moves 101-120 is not available. Cannot copy to later move bins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GameID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Winning Chances Column based on multiple tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# df= pd.read_csv(\"../Cleaned_Analyzed_Games/twic920_15_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume 'df' is your DataFrame with the analyzed games\n",
    "\n",
    "# Read and combine all winning chances tables\n",
    "winning_chances_tables = []\n",
    "for filename in glob.glob('../winning_chances_tables/winning_chances_moves_*.csv'):\n",
    "    # Extract the move bin from the filename\n",
    "    basename = os.path.basename(filename)\n",
    "    match = re.match(r'winning_chances_moves_(\\d+)-(\\d+)\\.csv', basename)\n",
    "    if match:\n",
    "        lower_move = int(match.group(1))\n",
    "        upper_move = int(match.group(2))\n",
    "        move_bin_label = f\"{lower_move}-{upper_move}\"\n",
    "        # Read the table\n",
    "        results_df = pd.read_csv(filename)\n",
    "        # Add the 'MoveBin' column\n",
    "        results_df['MoveBin'] = move_bin_label\n",
    "        # Append to the list\n",
    "        winning_chances_tables.append(results_df)\n",
    "\n",
    "# Combine all the winning chances tables\n",
    "winning_chances_combined = pd.concat(winning_chances_tables, ignore_index=True)\n",
    "\n",
    "# Prepare the main DataFrame 'df'\n",
    "\n",
    "# Ensure 'MoveNumber' is numeric\n",
    "df['MoveNumber'] = pd.to_numeric(df['MoveNumber'], errors='coerce')\n",
    "\n",
    "# Define the move bins as in the winning chances tables\n",
    "max_move_number = df['MoveNumber'].max()\n",
    "bin_size = 10  # 10 half-moves per bin (5 full moves)\n",
    "\n",
    "# Create edges for the bins\n",
    "edges = list(range(1, int(max_move_number) + bin_size + 1, bin_size))\n",
    "labels = [f\"{edges[i]}-{edges[i+1]-1}\" for i in range(len(edges)-1)]\n",
    "\n",
    "# Assign 'MoveBin' labels to 'MoveNumber' in df\n",
    "df['MoveBin'] = pd.cut(\n",
    "    df['MoveNumber'],\n",
    "    bins=edges,\n",
    "    labels=labels,\n",
    "    right=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Define evaluation intervals matching those in the winning chances tables\n",
    "intervals = np.arange(-20.2, 20.2 + 0.2, 0.2)  # Include upper limit\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "bin_labels = [f\"({intervals[i]}, {intervals[i+1]}]\" for i in range(len(intervals) - 1)]\n",
    "\n",
    "# Bin 'New_evaluations' in 'df' to create an 'Interval' column\n",
    "df['Interval'] = pd.cut(\n",
    "    df['Evaluation'],\n",
    "    bins=intervals,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Ensure 'MoveBin' and 'Interval' are strings for consistent merging\n",
    "df['MoveBin'] = df['MoveBin'].astype(str)\n",
    "df['Interval'] = df['Interval'].astype(str)\n",
    "winning_chances_combined['MoveBin'] = winning_chances_combined['MoveBin'].astype(str)\n",
    "winning_chances_combined['Interval'] = winning_chances_combined['Interval'].astype(str)\n",
    "\n",
    "# Merge 'df' with 'winning_chances_combined' on 'MoveBin' and 'Interval' to get 'WinningChance' and 'LosingChance'\n",
    "df = df.merge(\n",
    "    winning_chances_combined[['MoveBin', 'Interval', 'WinningChance', 'LosingChance', 'TotalGames']],\n",
    "    on=['MoveBin', 'Interval'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now 'df' has the 'Winning_Chance' and 'LosingChance' columns added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WCL'] = df.groupby('GameID')['WinningChance'].diff().abs()\n",
    "df['LCL'] = df.groupby('GameID')['LosingChance'].diff().abs()\n",
    "df.loc[df['MoveNumber'] % 2 == 0, 'WCL'] = None\n",
    "df.loc[df['MoveNumber'] % 2 != 0, 'LCL'] = None\n",
    "df.to_csv(\"../huge_analyzed_games/combined_analyzed_games_wc_move.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Winning Chances Column based on ONE table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df= pd.read_csv(\"../Cleaned_Analyzed_Games/twic920_15_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Read the 'winning_chances_all_moves.csv' Table\n",
    "results_df = pd.read_csv('winning_chances_all_moves.csv')\n",
    "\n",
    "# Step 2: Define Evaluation Intervals and Bin Labels\n",
    "# The intervals and bin labels should match those used when creating 'winning_chances_all_moves.csv'\n",
    "\n",
    "# Recreate the edges and bin labels\n",
    "intervals = np.arange(-13, 13.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "# Ensure that the bin labels in 'results_df' match the ones we're creating\n",
    "# This is important for a correct merge\n",
    "results_df['Interval'] = results_df['Interval'].astype(str)\n",
    "bin_labels = [str(label) for label in bin_labels]\n",
    "\n",
    "# Step 3: Bin the 'Evaluation' Values in 'df' to Create an 'Interval' Column\n",
    "# Assuming 'df' is your analyzed chess DataFrame and 'Evaluation' column exists\n",
    "df['Interval'] = pd.cut(\n",
    "    df['Evaluation'],\n",
    "    bins=edges,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Step 4: Merge 'df' with 'results_df' on 'Interval'\n",
    "# Select the columns to merge\n",
    "columns_to_merge = ['Interval', 'WinningChance', 'LosingChance', 'TotalGames']\n",
    "\n",
    "# Ensure 'Interval' in 'df' is of type string\n",
    "df['Interval'] = df['Interval'].astype(str)\n",
    "\n",
    "# Perform the merge\n",
    "df = df.merge(\n",
    "    results_df[columns_to_merge],\n",
    "    on='Interval',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now 'df' has the new columns added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WCL'] = df.groupby('GameID')['WinningChance'].diff().abs()\n",
    "df['LCL'] = df.groupby('GameID')['LosingChance'].diff().abs()\n",
    "df.loc[df['MoveNumber'] % 2 == 0, 'WCL'] = None\n",
    "df.loc[df['MoveNumber'] % 2 != 0, 'LCL'] = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
