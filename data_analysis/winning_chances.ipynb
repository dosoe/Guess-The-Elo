{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "#df = pd.read_csv(\"../Analyzed_Games/twic1556_15_analyzed.csv\")\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "#df= pd.read_csv(\"../Analyzed_Games/twic920_15_analyzed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Winning Chance for each position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Evaluation to numeric (For example, M6 means Mate in 6, we convert it to +20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Evaluation'] = df['Evaluation'].astype(str).str.strip()\n",
    "df['PlayerToMove'] = np.where(df['MoveNumber'] % 2 == 1, 'White', 'Black')\n",
    "\n",
    "# Function to convert 'Evaluation' to 'New_evaluations'\n",
    "def convert_evaluation(row):\n",
    "    \"\"\"\n",
    "    Convert the evaluation M to a numeric value.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A row from a DataFrame containing the 'Evaluation' column.\n",
    "\n",
    "    Returns:\n",
    "    float: The numeric evaluation value. Returns 0.0 for mate in 0 moves, 20.0 if White can mate, -20.0 if Black can mate, \n",
    "           the numeric evaluation if it can be parsed, or NaN if the evaluation cannot be parsed.\n",
    "    \"\"\"\n",
    "    eval_str = row['Evaluation']\n",
    "    \n",
    "    if eval_str in ['+M0', '-M0', 'M0']:\n",
    "        return 0.0  # Mate in 0 moves\n",
    "    elif eval_str.startswith('+M') or (eval_str.startswith('M') and not eval_str.startswith('-M')):\n",
    "        return 20.0  # White can mate\n",
    "    elif eval_str.startswith('-M'):\n",
    "        return -20.0  # Black can mate\n",
    "    else:\n",
    "        # Try to convert the evaluation to a float\n",
    "        try:\n",
    "            eval_float = float(eval_str)\n",
    "            return eval_float  # Numeric evaluation remains the same\n",
    "        except ValueError:\n",
    "            return np.nan  # Unable to parse evaluation\n",
    "\n",
    "# Apply the function to each row of df\n",
    "df['Evaluation'] = df.apply(convert_evaluation, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create auxillary functions get_outcome and calculate_chances\n",
    "\n",
    "calculate_chances calculates the chances of winning, losing and drawing for a given evaluation range based on all previous games and gives the number of games in which this evaluation occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Result' to outcome from White's perspective\n",
    "def get_outcome(result):\n",
    "    if result == '1-0':\n",
    "        return 'Win'    # White won\n",
    "    elif result == '0-1':\n",
    "        return 'Loss'   # White lost\n",
    "    elif result == '1/2-1/2':\n",
    "        return 'Draw'   # Draw\n",
    "    else:\n",
    "        return None     # Exclude other results\n",
    "    \n",
    "    \n",
    "def calculate_chances(df, lower_eval, upper_eval):\n",
    "    \"\"\"\n",
    "    Calculate the chances of winning, drawing, and losing for positions within a specified evaluation range.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing chess game data with columns 'GameID', 'Evaluations', 'Result', etc.\n",
    "    lower_eval (float): The lower bound of the evaluation range.\n",
    "    upper_eval (float): The upper bound of the evaluation range.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing the winning chance, drawing chance, losing chance, total number of valid games, and outcome counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter positions where 'Evaluation' is between lower_eval and upper_eval\n",
    "    positions_in_range = df[(df['Evaluation'] >= lower_eval) & (df['Evaluation'] <= upper_eval)].copy()\n",
    "    \n",
    "    # Get unique GameIDs where this occurs\n",
    "    games_in_range = positions_in_range['GameID'].unique()\n",
    "    \n",
    "    # Get the results of these games\n",
    "    game_results = df[df['GameID'].isin(games_in_range)][['GameID', 'Result']].drop_duplicates()\n",
    "    \n",
    "    # Apply the mapping\n",
    "    game_results['Outcome'] = game_results['Result'].apply(get_outcome)\n",
    "    \n",
    "    # Exclude games with 'Other' outcomes\n",
    "    valid_results = game_results.dropna(subset=['Outcome'])\n",
    "    \n",
    "    # Total number of valid games\n",
    "    total_valid_games = valid_results.shape[0]\n",
    "    outcome_counts=None\n",
    "    if total_valid_games == 0:\n",
    "        winning_chance = drawing_chance = losing_chance = 0.0\n",
    "    else:\n",
    "        # Count the number of games in each category\n",
    "        outcome_counts = valid_results['Outcome'].value_counts()\n",
    "        \n",
    "        # Calculate percentages\n",
    "        winning_chance = (outcome_counts.get('Win', 0) / total_valid_games) * 100\n",
    "        drawing_chance = (outcome_counts.get('Draw', 0) / total_valid_games) * 100\n",
    "        losing_chance = (outcome_counts.get('Loss', 0) / total_valid_games) * 100\n",
    "    \n",
    "    return [winning_chance, drawing_chance, losing_chance, total_valid_games,outcome_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the functions to all games and all evaluations, to get a table of winning, drawing and losing chance for each evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation bins\n",
    "intervals = np.arange(-20.2, 20.2, 0.2)\n",
    "intervals = np.round(intervals, decimals=1)\n",
    "# Prepare a list to hold the results\n",
    "results = []\n",
    "\n",
    "# Loop over intervals\n",
    "for i in range(len(intervals) - 1):\n",
    "    lower_eval = intervals[i]\n",
    "    upper_eval = intervals[i + 1]\n",
    "    \n",
    "    # Call the calculate_chances function\n",
    "    winning_chance, drawing_chance, losing_chance, total_valid_games = calculate_chances(df, lower_eval, upper_eval)[:4]\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Interval': f\"({lower_eval}, {upper_eval}]\",\n",
    "        'LowerEval': lower_eval,\n",
    "        'UpperEval': upper_eval,\n",
    "        'WinningChance': winning_chance,\n",
    "        'DrawingChance': drawing_chance,\n",
    "        'LosingChance': losing_chance,\n",
    "        'TotalGames': total_valid_games,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Now, adjust the DataFrame to fill intervals with TotalGames == 0\n",
    "# Find the closest interval with TotalGames > 0 and copy its chances\n",
    "\n",
    "# Create a DataFrame of intervals with TotalGames > 0\n",
    "non_zero_df = results_df[results_df['TotalGames'] > 0].reset_index(drop=True)\n",
    "\n",
    "# Function to fill in chances for intervals with TotalGames == 0\n",
    "def fill_chances(row):\n",
    "    if row['TotalGames'] > 0:\n",
    "        # Keep original values\n",
    "        return row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "    else:\n",
    "        lower_eval = row['LowerEval']\n",
    "        # Compute absolute difference in LowerEval\n",
    "        diffs = (non_zero_df['LowerEval'] - lower_eval).abs()\n",
    "        min_idx = diffs.idxmin()\n",
    "        closest_row = non_zero_df.loc[min_idx]\n",
    "        return closest_row[['WinningChance', 'DrawingChance', 'LosingChance']]\n",
    "\n",
    "# Apply the function to fill in the missing chances\n",
    "filled_chances = results_df.apply(fill_chances, axis=1)\n",
    "\n",
    "# Assign the filled values back to the DataFrame\n",
    "results_df[['WinningChance', 'DrawingChance', 'LosingChance']] = filled_chances\n",
    "\n",
    "# Remove the 'LowerEval' and 'UpperEval' columns\n",
    "results_df = results_df.drop(columns=['LowerEval', 'UpperEval'])\n",
    "\n",
    "#results_df.to_csv('winning_chances.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some evaluations are rare, so results could be skewed. In particular, the evaluation reflects the state of the game. Thus, the winning chance should be monotonically increasing with evaluation, so we impose this on the win and loss chance table. \n",
    "\n",
    "We then save the table to memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the 'WinningChance' column to be monotonically increasing\n",
    "winning_chances = results_df['WinningChance'].values\n",
    "for i in range(1, len(winning_chances)):\n",
    "    if winning_chances[i] < winning_chances[i-1]:\n",
    "        winning_chances[i] = winning_chances[i-1]\n",
    "results_df['WinningChance'] = winning_chances\n",
    "\n",
    "# Adjust the 'LosingChance' column to be monotonically decreasing\n",
    "losing_chances = results_df['LosingChance'].values\n",
    "for i in range(len(losing_chances)-2, -1, -1):\n",
    "    if losing_chances[i] < losing_chances[i+1]:\n",
    "        losing_chances[i] = losing_chances[i+1]\n",
    "results_df['LosingChance'] = losing_chances\n",
    "\n",
    "# Save the modified DataFrame back to CSV\n",
    "results_df.to_csv('winning_chances_adjusted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Winning Chance Loss for each move\n",
    "\n",
    "We start by reading the games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games.csv\")\n",
    "#df= pd.read_csv(\"../Cleaned_Analyzed_Games/twic920_15_processed.csv\")\n",
    "df=pd.read_csv(\"../huge_analyzed_games/combined_analyzed_games_20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a table of games and a winning chance table and calculates for each move its WCL and LCL (Losing Chance Loss) as two nes columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chess_data(df, winning_chance_table=pd.read_csv('winning_chances_all_moves.csv'), intervals=np.arange(-13, 13.2, 0.2)):\n",
    "    \"\"\"\n",
    "    Processes chess data by binning evaluation values, merging with winning chances,\n",
    "    and computing WCL, LCL, Player, and 'a' columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing chess game data with 'Evaluation', 'GameID', and 'MoveNumber' columns.\n",
    "    winning_chance_table (pd.DataFrame): DataFrame containing winning chances with 'Interval', 'WinningChance', 'LosingChance', and 'TotalGames' columns.\n",
    "    intervals (np.array): Numpy array of interval edges used for binning evaluations.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Modified DataFrame with additional columns added.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Ensure intervals are rounded to one decimal place\n",
    "    intervals = np.round(intervals, decimals=1)\n",
    "    edges = [-np.inf] + list(intervals) + [np.inf]\n",
    "\n",
    "    # Create bin labels\n",
    "    bin_labels = []\n",
    "    for i in range(len(edges) - 1):\n",
    "        lower = edges[i]\n",
    "        upper = edges[i + 1]\n",
    "        if np.isneginf(lower):\n",
    "            label = f\"(-infty, {upper}]\"\n",
    "        elif np.isposinf(upper):\n",
    "            label = f\"({lower}, infty)\"\n",
    "        else:\n",
    "            label = f\"({lower}, {upper}]\"\n",
    "        bin_labels.append(label)\n",
    "\n",
    "    # Ensure that the bin labels in 'winning_chance_table' match the ones we're creating\n",
    "    # This is important for a correct merge\n",
    "    winning_chance_table['Interval'] = winning_chance_table['Interval'].astype(str)\n",
    "    bin_labels = [str(label) for label in bin_labels]\n",
    "\n",
    "    # Bin the 'Evaluation' values in 'df' to create an 'Interval' column\n",
    "    df['Interval'] = pd.cut(\n",
    "        df['Evaluation'],\n",
    "        bins=edges,\n",
    "        labels=bin_labels,\n",
    "        right=True,\n",
    "        include_lowest=True,\n",
    "    )\n",
    "\n",
    "    # Ensure 'Interval' in 'df' is of type string\n",
    "    df['Interval'] = df['Interval'].astype(str)\n",
    "\n",
    "    # Select the columns to merge\n",
    "    columns_to_merge = ['Interval', 'WinningChance', 'LosingChance', 'TotalGames']\n",
    "\n",
    "    # Merge 'df' with 'winning_chance_table' on 'Interval'\n",
    "    df = df.merge(\n",
    "        winning_chance_table[columns_to_merge],\n",
    "        on='Interval',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Compute 'WCL' and 'LCL' differences per game\n",
    "    df['WCL'] = df.groupby('GameID')['WinningChance'].diff().abs()\n",
    "    df['LCL'] = df.groupby('GameID')['LosingChance'].diff().abs()\n",
    "\n",
    "    # Assign 'Player' based on move number\n",
    "    df['Player'] = np.where(df['MoveNumber'] % 2 != 0, 'White', 'Black')\n",
    "\n",
    "    # Compute 'a' = max(|WCL|, |LCL|) for each move\n",
    "    df['a'] = df[['WCL', 'LCL']].abs().max(axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is then applied to all games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=process_chess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning the WCL into mistake bins\n",
    "\n",
    "This function creates a new DataFrame that contains two lines per game: one for White, containing his Name, Elo, Color, the properties of the Game (Opening, GameID etc) and the number of mistakes they made, binned by gravity (`mistake_bins`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(df, mistake_bins= [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100], winning_chance_table=None, intervals=None):\n",
    "    \"\"\"\n",
    "    Processes the chess DataFrame to create a summary table of mistakes per interval per player per game.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing chess game data.\n",
    "    mistake_bins (list): List of bin edges for mistake intervals.\n",
    "    winning_chance_table (pd.DataFrame, optional): DataFrame containing winning chances.\n",
    "                                         Default is loaded from 'winning_chances_all_moves.csv'.\n",
    "    intervals (np.array, optional): Numpy array of interval edges used for binning evaluations.\n",
    "                                    Default is np.arange(-13, 13.2, 0.2).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Summary table with mistakes per interval per player per game.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # If 'WCL' does not exist, apply the 'process_chess_data' function\n",
    "    if 'WCL' not in df.columns or 'a' not in df.columns:\n",
    "        if winning_chance_table is None:\n",
    "            winning_chance_table = pd.read_csv('winning_chances_adjusted.csv')\n",
    "        if intervals is None:\n",
    "            intervals = np.arange(-13, 13.2, 0.2)\n",
    "        df = process_chess_data(df, winning_chance_table, intervals)\n",
    "\n",
    "    # Step 1: Define mistake labels based on mistake_bins\n",
    "    mistake_labels = []\n",
    "    for i in range(len(mistake_bins)-1):\n",
    "        label = f'({mistake_bins[i]},{mistake_bins[i+1]}]'\n",
    "        mistake_labels.append(label)\n",
    "\n",
    "    # Step 2: Assign each 'a' to a mistake interval\n",
    "    df['MistakeInterval'] = pd.cut(\n",
    "        df['a'],\n",
    "        bins=mistake_bins,\n",
    "        labels=mistake_labels,\n",
    "        right=True,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    # Step 3: Identify the player making the move if 'Player' column doesn't exist\n",
    "    if 'Player' not in df.columns:\n",
    "        df['Player'] = np.where(df['MoveNumber'] % 2 != 0, 'White', 'Black')\n",
    "\n",
    "    # Step 4: Group and count the number of mistakes per interval, per player, per game\n",
    "    mistake_moves = df.dropna(subset=['MistakeInterval'])\n",
    "    mistake_counts = mistake_moves.groupby(['GameID', 'Player', 'MistakeInterval']).size().reset_index(name='MistakeCount')\n",
    "\n",
    "    # Step 5: Pivot the data to get a summary table per game and player\n",
    "    summary_table = mistake_counts.pivot_table(\n",
    "        index=['GameID', 'Player'],\n",
    "        columns='MistakeInterval',\n",
    "        values='MistakeCount',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "\n",
    "    # Flatten the column MultiIndex if necessary\n",
    "    summary_table.columns.name = None\n",
    "    summary_table.columns = [col if isinstance(col, str) else col for col in summary_table.columns]\n",
    "\n",
    "    # Step 6: Compute Total Moves per game\n",
    "    total_moves = df.groupby('GameID')['MoveNumber'].max().reset_index(name='TotalMoves')\n",
    "\n",
    "    # Step 7: Extract game-level metadata: Opening, Variation, Result\n",
    "    game_metadata = df.groupby('GameID').agg({\n",
    "        'Opening': 'first',\n",
    "        'Variation': 'first',\n",
    "        'Result': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Merge TotalMoves into game_metadata\n",
    "    game_metadata = game_metadata.merge(total_moves, on='GameID', how='left')\n",
    "\n",
    "    # Step 8: Extract player-level metadata\n",
    "    player_metadata = df.groupby('GameID').agg({\n",
    "        'WhiteName': 'first',\n",
    "        'WhiteElo': 'first',\n",
    "        'WhiteFideId': 'first',\n",
    "        'BlackName': 'first',\n",
    "        'BlackElo': 'first',\n",
    "        'BlackFideId': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Prepare player metadata for merging\n",
    "    # For White players\n",
    "    white_players = player_metadata[['GameID', 'WhiteName', 'WhiteElo', 'WhiteFideId']].copy()\n",
    "    white_players['Player'] = 'White'\n",
    "    white_players = white_players.rename(columns={\n",
    "        'WhiteName': 'Name',\n",
    "        'WhiteElo': 'Elo',\n",
    "        'WhiteFideId': 'FideId'\n",
    "    })\n",
    "\n",
    "    # For Black players\n",
    "    black_players = player_metadata[['GameID', 'BlackName', 'BlackElo', 'BlackFideId']].copy()\n",
    "    black_players['Player'] = 'Black'\n",
    "    black_players = black_players.rename(columns={\n",
    "        'BlackName': 'Name',\n",
    "        'BlackElo': 'Elo',\n",
    "        'BlackFideId': 'FideId'\n",
    "    })\n",
    "\n",
    "    # Concatenate player metadata\n",
    "    player_metadata_long = pd.concat([white_players, black_players], ignore_index=True)\n",
    "\n",
    "    # Step 9: Merge player metadata with the summary table\n",
    "    summary_table = summary_table.merge(player_metadata_long, on=['GameID', 'Player'], how='left')\n",
    "\n",
    "    # Step 10: Merge game metadata with the summary table\n",
    "    summary_table = summary_table.merge(game_metadata, on='GameID', how='left')\n",
    "    total_moves_bins = [0, 30, 40, 50, 60, 70, 80, 90, 100, 120, np.inf]\n",
    "    total_moves_labels = [\n",
    "        '(0,30]', '(30,40]', '(40,50]', '(50,60]', '(60,70]',\n",
    "        '(70,80]', '(80,90]', '(90,100]', '(100,120]', '(120,∞)'\n",
    "    ]\n",
    "\n",
    "    # Step 2: Assign each game to a TotalMovesInterval\n",
    "    summary_table['TotalMovesInterval'] = pd.cut(\n",
    "        summary_table['TotalMoves'],\n",
    "        bins=total_moves_bins,\n",
    "        labels=total_moves_labels,\n",
    "        right=True,\n",
    "        include_lowest=True\n",
    "    )\n",
    "    # Rearranging columns for better readability\n",
    "    cols = ['GameID', 'Player', 'Name', 'Elo', 'FideId', 'Opening', 'Variation', 'Result', 'TotalMoves', 'TotalMovesInterval'] + mistake_labels\n",
    "    summary_table = summary_table[cols]\n",
    "\n",
    "    return summary_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_67068\\521829234.py:48: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mistake_counts = mistake_moves.groupby(['GameID', 'Player', 'MistakeInterval']).size().reset_index(name='MistakeCount')\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_67068\\521829234.py:51: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  summary_table = mistake_counts.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "summary_table=create_summary_table(df)\n",
    "#summary_table.to_csv(\"../huge_analyzed_games/big_summary_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_85248\\521829234.py:48: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  mistake_counts = mistake_moves.groupby(['GameID', 'Player', 'MistakeInterval']).size().reset_index(name='MistakeCount')\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_85248\\521829234.py:51: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  summary_table = mistake_counts.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "table=create_summary_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "df= pd.read_csv(\"../Cleaned_Analyzed_Games/twic920_15_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_bins= [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "mistake_labels = []\n",
    "for i in range(len(mistake_bins)-1):\n",
    "    label = f'({mistake_bins[i]},{mistake_bins[i+1]}]'\n",
    "    mistake_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_67068\\3311506717.py:49: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_67068\\3311506717.py:49: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_67068\\3311506717.py:49: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_67068\\3311506717.py:49: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 265.69\n",
      "R-squared Score (R²): 0.12\n",
      "Percentage of predictions within ±300 Elo: 75.97%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your summary_table\n",
    "#summary_table = pd.read_csv(\"../huge_analyzed_games/big_summary_table.csv\")\n",
    "\n",
    "# Define the mistake intervals and labels\n",
    "mistake_bins = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 100]\n",
    "mistake_labels = []\n",
    "for i in range(len(mistake_bins)-1):\n",
    "    label = f'({mistake_bins[i]},{mistake_bins[i+1]}]'\n",
    "    mistake_labels.append(label)\n",
    "\n",
    "# Ensure 'TotalMovesInterval' is added to summary_table\n",
    "total_moves_bins = [0, 30, 40, 50, 60, 70, 80, 90, 100, 120, np.inf]\n",
    "total_moves_labels = []\n",
    "for i in range(len(total_moves_bins)-1):\n",
    "    lower = total_moves_bins[i]\n",
    "    upper = total_moves_bins[i+1]\n",
    "    if np.isinf(upper):\n",
    "        label = f'({lower},∞]'\n",
    "    else:\n",
    "        label = f'({lower},{upper}]'\n",
    "    total_moves_labels.append(label)\n",
    "    \n",
    "summary_table['TotalMovesInterval'] = pd.cut(\n",
    "    summary_table['TotalMoves'],\n",
    "    bins=total_moves_bins,\n",
    "    labels=total_moves_labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Handle missing values in the target variable\n",
    "summary_table = summary_table.dropna(subset=['Elo'])\n",
    "\n",
    "# Handle missing values in categorical features by adding 'Unknown' to categories\n",
    "categorical_features = ['Opening', 'Variation', 'Result', 'TotalMovesInterval', 'Player']\n",
    "\n",
    "for col in categorical_features:\n",
    "    # Ensure the column is of 'category' dtype\n",
    "    if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
    "        summary_table[col] = summary_table[col].astype('category')\n",
    "    # Add 'Unknown' to categories if not already present\n",
    "    if 'Unknown' not in summary_table[col].cat.categories:\n",
    "        summary_table[col] = summary_table[col].cat.add_categories(['Unknown'])\n",
    "    # Fill NaN values with 'Unknown'\n",
    "    summary_table[col] = summary_table[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features (mistake intervals)\n",
    "mistake_intervals = mistake_labels  # List of mistake interval columns\n",
    "summary_table[mistake_intervals] = summary_table[mistake_intervals].fillna(0)\n",
    "\n",
    "# Step 1: Read the 'winning_chances_all_moves.csv' Table\n",
    "results_df = pd.read_csv('winning_chances_all_moves.csv')\n",
    "\n",
    "# Define the features\n",
    "feature_columns = ['Opening',  'Result', 'TotalMovesInterval', ] + mistake_intervals\n",
    "X = summary_table[feature_columns]\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = ['Opening', 'Result', 'TotalMovesInterval', ]\n",
    "numerical_features = mistake_intervals\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create a ColumnTransformer to apply OneHotEncoder to categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through numerical features without changes\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared Score (R²): {r2:.2f}')\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = []\n",
    "for i in range(len(edges) - 1):\n",
    "    lower = edges[i]\n",
    "    upper = edges[i + 1]\n",
    "    if np.isneginf(lower):\n",
    "        label = f\"(-infty, {upper}]\"\n",
    "    elif np.isposinf(upper):\n",
    "        label = f\"({lower}, infty)\"\n",
    "    else:\n",
    "        label = f\"({lower}, {upper}]\"\n",
    "    bin_labels.append(label)\n",
    "\n",
    "print(f\"Percentage of predictions within ±{threshold} Elo: {percentage_within_threshold:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_85248\\3384362917.py:18: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(player_games[col]):\n"
     ]
    }
   ],
   "source": [
    "# Specify the player's name or FIDE ID\n",
    "player_name = 'Caruana Fabiano'  # Replace with the player's name\n",
    "player_fide_id = 2020009       # Replace with the player's FIDE ID (if available)\n",
    "\n",
    "# Extract the 5 games for the player\n",
    "player_games = summary_table[\n",
    "    (summary_table['Name'] == player_name) | (summary_table['FideId'] == player_fide_id)\n",
    "].head(10)  # Get the first 5 games\n",
    "\n",
    "# If you have specific GameIDs\n",
    "#game_ids = [1, 2, 3, 4, 5]  # Replace with the actual GameIDs\n",
    "#player_games = summary_table[summary_table['GameID'].isin(game_ids)]\n",
    "# Handle missing values in categorical features\n",
    "categorical_features = ['Opening', 'Variation', 'Result', 'TotalMovesInterval', 'Player']\n",
    "\n",
    "for col in categorical_features:\n",
    "    # Ensure the column is of 'category' dtype\n",
    "    if not pd.api.types.is_categorical_dtype(player_games[col]):\n",
    "        player_games[col] = player_games[col].astype('category')\n",
    "    # Add 'Unknown' to categories if not already present\n",
    "    if 'Unknown' not in player_games[col].cat.categories:\n",
    "        player_games[col] = player_games[col].cat.add_categories(['Unknown'])\n",
    "    # Fill NaN values with 'Unknown'\n",
    "    player_games[col] = player_games[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features (mistake intervals)\n",
    "player_games[mistake_intervals] = player_games[mistake_intervals].fillna(0)\n",
    "\n",
    "# Define the features\n",
    "feature_columns = ['Opening', 'Variation', 'Result', 'TotalMovesInterval', 'Player'] + mistake_intervals\n",
    "X_player = player_games[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Elo for Game 1: 2258.58\n",
      "Predicted Elo for Game 2: 2216.70\n",
      "Predicted Elo for Game 3: 2371.31\n",
      "Predicted Elo for Game 4: 2376.94\n",
      "Predicted Elo for Game 5: 2287.00\n",
      "Predicted Elo for Game 6: 2467.72\n",
      "Predicted Elo for Game 7: 2269.58\n",
      "Predicted Elo for Game 8: 2402.88\n",
      "Predicted Elo for Game 9: 2242.95\n",
      "Predicted Elo for Game 10: 2418.32\n",
      "\n",
      "Average Predicted Elo for Caruana Fabiano: 2331.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_85248\\587716437.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(player_games[col]):\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in categorical features\n",
    "categorical_features = ['Opening', 'Variation', 'Result', 'TotalMovesInterval', 'Player']\n",
    "\n",
    "for col in categorical_features:\n",
    "    # Ensure the column is of 'category' dtype\n",
    "    if not pd.api.types.is_categorical_dtype(player_games[col]):\n",
    "        player_games[col] = player_games[col].astype('category')\n",
    "    # Add 'Unknown' to categories if not already present\n",
    "    if 'Unknown' not in player_games[col].cat.categories:\n",
    "        player_games[col] = player_games[col].cat.add_categories(['Unknown'])\n",
    "    # Fill NaN values with 'Unknown'\n",
    "    player_games[col] = player_games[col].fillna('Unknown')\n",
    "\n",
    "# Handle missing values in numerical features (mistake intervals)\n",
    "player_games[mistake_intervals] = player_games[mistake_intervals].fillna(0)\n",
    "\n",
    "# Define the features\n",
    "feature_columns = ['Opening', 'Variation', 'Result', 'TotalMovesInterval', 'Player'] + mistake_intervals\n",
    "X_player = player_games[feature_columns]\n",
    "\n",
    "y_player_pred = pipeline.predict(X_player)\n",
    "\n",
    "# Print the predictions for each game\n",
    "for i, pred in enumerate(y_player_pred):\n",
    "    print(f\"Predicted Elo for Game {i+1}: {pred:.2f}\")\n",
    "    \n",
    "average_predicted_elo = y_player_pred.mean()\n",
    "print(f\"\\nAverage Predicted Elo for {player_name}: {average_predicted_elo:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_21700\\926839676.py:46: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_21700\\926839676.py:46: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_21700\\926839676.py:46: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n",
      "C:\\Users\\foivo\\AppData\\Local\\Temp\\ipykernel_21700\\926839676.py:46: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if not pd.api.types.is_categorical_dtype(summary_table[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 269.73\n",
      "R-squared Score (R²): 0.08\n",
      "\n",
      "Top 20 features by absolute coefficient value:\n",
      "                                               Feature  Coefficient\n",
      "254                             Opening_Scotch opening  -451.073717\n",
      "130    Opening_King's Indian Defense: Kazakh Variation  -415.913072\n",
      "36                              Opening_Canard opening  -372.655133\n",
      "282  Opening_Trompowsky Attack: Classical Defense, ...   357.048160\n",
      "112                   Opening_Gruenfeld with e3    Bd3  -334.868810\n",
      "206                             Opening_Queen's Gambit  -328.209702\n",
      "270  Opening_Sicilian, Szen variation, Dely-Kasparo...  -319.903968\n",
      "52                           Opening_Damiano's defence  -317.661726\n",
      "40                           Opening_Caro-Masi defence  -314.348275\n",
      "181          Opening_Pirc Defense: Classical Variation   286.606038\n",
      "293          Opening_Vienna gambit, Steinitz variation   266.532981\n",
      "294             Opening_Vienna gambit, Wurzburger trap  -256.344930\n",
      "31        Opening_Bogo-Indian defence, Monticelli trap   247.059421\n",
      "207  Opening_Queen's Gambit Declined: Exchange Vari...   244.824753\n",
      "237  Opening_Ruy Lopez: Morphy Defense, Arkhangelsk...   244.053123\n",
      "239         Opening_Ruy Lopez: Open, Classical Defense   240.549104\n",
      "43                     Opening_Catalan Opening: Closed   240.087293\n",
      "137                     Opening_King's knight's gambit  -235.160078\n",
      "263  Opening_Sicilian Defense: Nyezhmetdinov-Rossol...  -234.867064\n",
      "262  Opening_Sicilian Defense: Dragon Variation, Fi...   232.882765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 3: Bin the 'Evaluation' Values in 'df' to Create an 'Interval' Column\n",
    "# Assuming 'df' is your analyzed chess DataFrame and 'Evaluation' column exists\n",
    "df['Interval'] = pd.cut(\n",
    "    df['Evaluation'],\n",
    "    bins=edges,\n",
    "    labels=bin_labels,\n",
    "    right=True,\n",
    "    include_lowest=True,\n",
    ")\n",
    "\n",
    "# Step 4: Merge 'df' with 'results_df' on 'Interval'\n",
    "# Select the columns to merge\n",
    "columns_to_merge = ['Interval', 'WinningChance', 'LosingChance', 'TotalGames']\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared Score (R²): {r2:.2f}')\n",
    "\n",
    "# Get the names of the categorical features after one-hot encoding\n",
    "onehot_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine with numerical feature names\n",
    "all_feature_names = np.concatenate([onehot_feature_names, numerical_features])\n",
    "\n",
    "# Get the coefficients from the linear regression model\n",
    "coefficients = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame to display feature names and their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort the coefficients by absolute value\n",
    "coef_df['AbsCoefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df = coef_df.sort_values(by='AbsCoefficient', ascending=False)\n",
    "\n",
    "# Display the top 20 features with the highest absolute coefficients\n",
    "print(\"\\nTop 20 features by absolute coefficient value:\")\n",
    "print(coef_df[['Feature', 'Coefficient']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 266.19\n",
      "R-squared Score (R²): 0.11\n",
      "Percentage of predictions within ±300 Elo: 77.62%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared Score (R²): {r2:.2f}')\n",
    "\n",
    "# Calculate the percentage of predictions within ±300 Elo\n",
    "absolute_errors = np.abs(y_pred - y_test)\n",
    "threshold = 300\n",
    "within_threshold = np.sum(absolute_errors <= threshold)\n",
    "total_predictions = len(y_test)\n",
    "percentage_within_threshold = (within_threshold / total_predictions) * 100\n",
    "\n",
    "print(f\"Percentage of predictions within ±{threshold} Elo: {percentage_within_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['(3,5]'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 18\u001b[0m\n\u001b[0;32m     12\u001b[0m mistake_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(3,5]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(5,10]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(10,15]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(15,20]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(20,25]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(25,30]\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(30,35]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(35,40]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(40,50]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(50,60]\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m ]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Handle missing values in mistake intervals\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m summary_table_white[mistake_labels] \u001b[38;5;241m=\u001b[39m summary_table_white[mistake_labels]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure 'Elo' is numeric\u001b[39;00m\n\u001b[0;32m     21\u001b[0m summary_table_white[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElo\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(summary_table_white[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElo\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\foivo\\anaconda3\\envs\\guess_the_elo-env\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\foivo\\anaconda3\\envs\\guess_the_elo-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\foivo\\anaconda3\\envs\\guess_the_elo-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['(3,5]'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your summary_table\n",
    "#summary_table = pd.read_csv(\"../huge_analyzed_games/big_summary_table.csv\")\n",
    "\n",
    "# Filter data for White players only\n",
    "summary_table_white = summary_table[summary_table['Player'] == 'White']\n",
    "\n",
    "# Define the mistake intervals and labels\n",
    "mistake_labels = [\n",
    "    '(3,5]', '(5,10]', '(10,15]', '(15,20]', '(20,25]', '(25,30]',\n",
    "    '(30,35]', '(35,40]', '(40,50]', '(50,60]', \n",
    "]\n",
    "\n",
    "# Handle missing values in mistake intervals\n",
    "summary_table_white[mistake_labels] = summary_table_white[mistake_labels].fillna(0)\n",
    "\n",
    "# Ensure 'Elo' is numeric\n",
    "summary_table_white['Elo'] = pd.to_numeric(summary_table_white['Elo'], errors='coerce')\n",
    "\n",
    "# Remove rows with missing 'Elo' values\n",
    "summary_table_white = summary_table_white.dropna(subset=['Elo'])\n",
    "\n",
    "# Step 1: Bin the Elo Ratings\n",
    "# Define Elo rating bins\n",
    "elo_bins = [0, 1200, 1400, 1600, 1800, 2000, 2200, 2400, 2600, 2800, np.inf]\n",
    "elo_labels = ['<1200', '1200-1399', '1400-1599', '1600-1799', '1800-1999',\n",
    "              '2000-2199', '2200-2399', '2400-2599', '2600-2799', '2800+']\n",
    "\n",
    "# Perform the merge\n",
    "df = df.merge(\n",
    "    results_df[columns_to_merge],\n",
    "    on='Interval',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now 'df' has the new columns added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WCL'] = df.groupby('GameID')['WinningChance'].diff().abs()\n",
    "df['LCL'] = df.groupby('GameID')['LosingChance'].diff().abs()\n",
    "df.loc[df['MoveNumber'] % 2 == 0, 'WCL'] = None\n",
    "df.loc[df['MoveNumber'] % 2 != 0, 'LCL'] = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guess_the_elo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
